def test_c6_hdfs(self):
    print '\nLoad a list of files from HDFS, parse and do 1 RF tree'
    print '\nYou can try running as hduser/hduser if fail'
    csvFilenameAll = ['TEST-poker1000.csv', 'and-testing.data', 'arcene2_train.both', 'arcene_train.both', 'bestbuy_test.csv', 'bestbuy_train.csv', 'covtype.13x.data', 'covtype.13x.shuffle.data', 'covtype.4x.shuffle.data', 'covtype.data', 'covtype4x.shuffle.data', 'hhp.unbalanced.012.1x11.data.gz', 'hhp.unbalanced.012.data.gz', 'hhp.unbalanced.data.gz', 'hhp_9_14_12.data', 'leads.csv', 'prostate_long_1G.csv']
    csvFilenameAll = ['covtype4x.shuffle.data', 'covtype4x.shuffle.data', 'covtype4x.shuffle.data', 'covtype4x.shuffle.data', 'covtype4x.shuffle.data', 'covtype4x.shuffle.data', 'covtype4x.shuffle.data', 'covtype4x.shuffle.data']
    h2o.setup_benchmark_log()
    benchmarkLogging = []
    if DO_RANDOM_SAMPLE:
        csvFilenameList = random.sample(csvFilenameAll, 8)
    else:
        csvFilenameList = csvFilenameAll
    importFolderPath = 'datasets'
    trial = 0
    for csvFilename in csvFilenameList:
        csvPathname = ((importFolderPath + '/') + csvFilename)
        timeoutSecs = 1000
        print 'Loading', csvFilename, 'from hdfs'
        start = time.time()
        parseResult = h2i.import_parse(path=csvPathname, schema='hdfs', timeoutSecs=timeoutSecs, doSummary=True, benchmarkLogging=benchmarkLogging)
        print 'parse result:', parseResult['destination_key']
        elapsed = (time.time() - start)
        l = '{!s} jvms, {!s}GB heap, {:s} {:s} for {:.2f} secs'.format(len(h2o.nodes), h2o.nodes[0].java_heap_GB, 'Parse', csvPathname, elapsed)
        print ('\n' + l)
        h2o.cloudPerfH2O.message(l)
        if DO_RF:
            print ('\n' + csvFilename)
            start = time.time()
            kwargs = {'ntree': 1, }
            paramsString = json.dumps(kwargs)
            RFview = h2o_cmd.runRF(parseResult=parseResult, timeoutSecs=2000, benchmarkLogging=benchmarkLogging, **kwargs)
            elapsed = (time.time() - start)
            print 'rf end on ', csvPathname, 'took', elapsed, 'seconds.', ('%d pct. of timeout' % ((elapsed / timeoutSecs) * 100))
            l = '{!s} jvms, {!s}GB heap, {:s} {:s} {:s} for {:.2f} secs {:s}'.format(len(h2o.nodes), h2o.nodes[0].java_heap_GB, 'RF', ('trial ' + str(trial)), csvFilename, elapsed, paramsString)
            print l
            h2o.cloudPerfH2O.message(l)
        if (1 == 0):
            print "Deleting all keys, to make sure our parse times don't include spills"
            h2i.delete_keys_at_all_nodes()
        trial += 1
