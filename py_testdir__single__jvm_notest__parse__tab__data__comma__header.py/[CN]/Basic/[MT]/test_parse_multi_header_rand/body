def test_parse_multi_header_rand(self):
    SYNDATASETS_DIR = h2o.make_syn_dir()
    csvFilename = 'syn_ints.csv'
    csvPathname = ((SYNDATASETS_DIR + '/') + csvFilename)
    allowedLetters = 'abcdeABCDE01234[]'
    headerChoices = []
    for n in range(20):
        l = random.randint(1, 64)
        headerName = ''.join([random.choice(allowedLetters) for _ in range(l)])
        headerChoices.append(headerName)
    tryList = [(1, 5, 9, 'cA', 60, 0), (1, 5, 25, 'cA', 60, 0)]
    for trial in range(50):
        (fileNum, rowCount, colCount, hex_key, timeoutSecs, dataRowsWithHeader) = random.choice(tryList)
        print fileNum, rowCount, colCount, hex_key, timeoutSecs, dataRowsWithHeader
        print 'Wait while', fileNum, 'synthetic files are created in', SYNDATASETS_DIR
        rowxcol = ((str(rowCount) + 'x') + str(colCount))
        totalCols = (colCount + 1)
        totalDataRows = 0
        totalHeaderRows = 0
        HEADER_HAS_HDR_ROW = 1
        DATA_HAS_HDR_ROW = 0
        PARSE_PATTERN_INCLUDES_HEADER = 0
        print "TEMPORARY: don't put any comments in"
        DATA_FIRST_IS_COMMENT = 0
        HEADER_FIRST_IS_COMMENT = 0
        SEP_CHAR_GEN = '\t'
        print '\nHEADER_HAS_HDR_ROW:', HEADER_HAS_HDR_ROW
        print 'DATA_HAS_HDR_ROW:', DATA_HAS_HDR_ROW
        print 'PARSE_PATTERN_INCLUDES_HEADER', PARSE_PATTERN_INCLUDES_HEADER
        print 'DATA_FIRST_IS_COMMENT:', DATA_FIRST_IS_COMMENT
        print 'HEADER_FIRST_IS_COMMENT:', HEADER_FIRST_IS_COMMENT
        print 'SEP_CHAR_GEN:', SEP_CHAR_GEN
        hh = ([random.choice(headerChoices) for h in range(colCount)] + ['output'])
        print hh
        print 'UPDATE: always use comma (space legal also?) for header separator?? it should work no matter what separator the data uses?'
        headerForHeader = ','.join(hh)
        hh = ([random.choice(headerChoices) for h in range(colCount)] + ['output'])
        headerForData = SEP_CHAR_GEN.join(hh)
        kwargs = {}
        for (k, v) in paramsDict.items():
            aChoice = random.choice(v)
            if (k == 'separator'):
                if aChoice:
                    sepChar = aChoice
                    sepCharInt = ord(aChoice)
                else:
                    sepChar = ','
                    sepCharInt = None
                aChoice = sepCharInt
            kwargs[k] = aChoice
        if kwargs['separator']:
            if ((SEP_CHAR_GEN == ' ') or (SEP_CHAR_GEN == ',')):
                del kwargs['separator']
            else:
                kwargs['separator'] = ord(SEP_CHAR_GEN)
        for fileN in range(fileNum):
            csvFilename = (((((((('syn_data_' + str(fileN)) + '_') + str(SEED)) + '_') + str(trial)) + '_') + rowxcol) + '.csv')
            csvPathname = ((SYNDATASETS_DIR + '/') + csvFilename)
            rList = rand_rowData(colCount, sepChar=SEP_CHAR_GEN)
            (headerRowsDone, dataRowsDone) = write_syn_dataset(csvPathname, rowCount, headerString=(headerForData if DATA_HAS_HDR_ROW else None), rList=rList, commentFirst=DATA_FIRST_IS_COMMENT, sepChar=SEP_CHAR_GEN)
            totalDataRows += dataRowsDone
            totalHeaderRows += headerRowsDone
        hdrFilename = (((((('syn_header_' + str(SEED)) + '_') + str(trial)) + '_') + rowxcol) + '.csv')
        hdrPathname = ((SYNDATASETS_DIR + '/') + hdrFilename)
        (headerRowsDone, dataRowsDone) = write_syn_dataset(hdrPathname, dataRowsWithHeader, headerString=(headerForHeader if HEADER_HAS_HDR_ROW else None), rList=rList, commentFirst=HEADER_FIRST_IS_COMMENT, sepChar=SEP_CHAR_GEN)
        if PARSE_PATTERN_INCLUDES_HEADER:
            totalDataRows += dataRowsDone
        totalHeaderRows += headerRowsDone
        hex_key = (('syn_dst' + str(trial)) + '.hex')
        xs = h2o.nodes[0].import_files(SYNDATASETS_DIR)['keys']
        headerKey = [x for x in xs if (hdrFilename in x)][0]
        dataKey = [x for x in xs if (csvFilename not in x)][0]
        print 'Header Key =', headerKey
        if (kwargs['header_from_file'] == 'syn_header'):
            kwargs['header_from_file'] = headerKey
        elif (kwargs['header_from_file'] == 'syn_data'):
            kwargs['header_from_file'] = dataKey
        if (not HEADER_HAS_HDR_ROW):
            kwargs['header_from_file'] = None
        print 'If header_from_file= is used, we are currently required to force header=1 for h2o'
        if kwargs['header_from_file']:
            kwargs['header'] = 1
        elif DATA_HAS_HDR_ROW:
            kwargs['header'] = 1
        else:
            kwargs['header'] = 0
        start = time.time()
        if (PARSE_PATTERN_INCLUDES_HEADER and HEADER_HAS_HDR_ROW):
            pattern = (((('*syn_*' + str(trial)) + '_') + rowxcol) + '*')
        else:
            pattern = (((('*syn_data_*' + str(trial)) + '_') + rowxcol) + '*')
        parseResult = h2i.parse_only(pattern=pattern, hex_key=hex_key, timeoutSecs=timeoutSecs, **kwargs)
        print ("parseResult['destination_key']: " + parseResult['destination_key'])
        inspect = h2o_cmd.runInspect(None, parseResult['destination_key'])
        h2o_cmd.infoFromInspect(inspect, csvPathname)
        print ('\n' + csvPathname), '    numRows:', '{:,}'.format(inspect['numRows']), '    numCols:', '{:,}'.format(inspect['numCols'])
        h2o_cmd.columnInfoFromInspect(parseResult['destination_key'], exceptionOnMissingValues=False)
        self.assertEqual(inspect['numCols'], totalCols, ('parse created result with the wrong number of cols %s %s' % (inspect['numCols'], totalCols)))
        h2oLosesOneData = ((headerRowsDone == 0) and (kwargs['header'] == 1) and (not DATA_HAS_HDR_ROW))
        h2oGainsOneData = ((headerRowsDone != 0) and (kwargs['header'] == 1) and DATA_HAS_HDR_ROW and (kwargs['header_from_file'] is not None))
        print 'h2oLosesOneData:', h2oLosesOneData
        print 'h2oGainsOneData:', h2oGainsOneData
        if h2oLosesOneData:
            totalDataRows -= 1
        if h2oGainsOneData:
            totalDataRows += 1
        self.assertEqual(inspect['numRows'], totalDataRows, ("parse created result with the wrong number of rows (header rows don't count) h2o: %s gen'ed: %s" % (inspect['numRows'], totalDataRows)))
        h2oShouldSeeHeader = ((HEADER_HAS_HDR_ROW and (kwargs['header_from_file'] is not None)) or DATA_HAS_HDR_ROW)
        if h2oShouldSeeHeader:
            kwargs = {'sample': 75, 'depth': 25, 'ntree': 1, 'ignore': 'A', }
        else:
            kwargs = {'sample': 75, 'depth': 25, 'ntree': 1, }
        start = time.time()
        elapsed = (time.time() - start)
        print ('%d pct. of timeout' % ((elapsed / timeoutSecs) * 100))
        print 'trial #', trial, 'totalDataRows:', totalDataRows, 'parse end on ', csvFilename, 'took', (time.time() - start), 'seconds'
        h2o.check_sandbox_for_errors()
