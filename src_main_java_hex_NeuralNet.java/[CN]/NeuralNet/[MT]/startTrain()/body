{
  Vec[] vecs=Utils.append(_train,response);
  reChunk(vecs);
  final Vec[] train=new Vec[vecs.length - 1];
  System.arraycopy(vecs,0,train,0,train.length);
  final Vec trainResp=classification ? vecs[vecs.length - 1].toEnum() : vecs[vecs.length - 1];
  final Layer[] ls=new Layer[hidden.length + 2];
  ls[0]=new VecsInput(train,null);
  for (int i=0; i < hidden.length; i++) {
switch (activation) {
case Tanh:
      ls[i + 1]=new Layer.Tanh(hidden[i]);
    break;
case Rectifier:
  ls[i + 1]=new Layer.Rectifier(hidden[i]);
break;
case RectifierWithDropout:
ls[i + 1]=new Layer.RectifierDropout(hidden[i]);
break;
case Maxout:
ls[i + 1]=new Layer.Maxout(hidden[i]);
break;
}
ls[i + 1].rate=(float)rate;
ls[i + 1].rate_annealing=(float)rate_annealing;
ls[i + 1].momentum_start=(float)momentum_start;
ls[i + 1].momentum_ramp=momentum_ramp;
ls[i + 1].momentum_stable=(float)momentum_stable;
ls[i + 1].l2=(float)l2;
}
if (classification) ls[ls.length - 1]=new VecSoftmax(trainResp,null);
 else ls[ls.length - 1]=new VecLinear(trainResp,null);
ls[ls.length - 1].rate=(float)rate;
ls[ls.length - 1].rate_annealing=(float)rate_annealing;
ls[ls.length - 1].l2=(float)l2;
for (int i=0; i < ls.length; i++) ls[i].init(ls,i);
final Key sourceKey=Key.make(input("source"));
final Frame frame=new Frame(_names,train);
frame.add(_responseName,trainResp);
final Errors[] trainErrors0=new Errors[]{new Errors()};
final Errors[] validErrors0=validation == null ? null : new Errors[]{new Errors()};
NeuralNetModel model=new NeuralNetModel(destination_key,sourceKey,frame,ls);
model.training_errors=trainErrors0;
model.validation_errors=validErrors0;
UKV.put(destination_key,model);
final Frame[] adapted=validation == null ? null : model.adapt(validation,false);
final Trainer trainer=new Trainer.MapReduce(ls,epochs,self());
Thread thread=new Thread(){
Errors[] trainErrors=trainErrors0, validErrors=validErrors0;
@Override public void run(){
try {
Vec[] valid=null;
Vec validResp=null;
if (validation != null) {
final Vec[] vs=adapted[0].vecs();
valid=Arrays.copyOf(vs,vs.length - 1);
System.arraycopy(adapted[0].vecs(),0,valid,0,valid.length);
validResp=vs[vs.length - 1];
}
while (!cancelled()) {
eval(valid,validResp);
try {
Thread.sleep(2000);
}
 catch (InterruptedException e) {
throw new RuntimeException(e);
}
}
eval(valid,validResp);
if (adapted != null && adapted[1] != null) adapted[1].remove();
}
 catch (Exception ex) {
cancel(ex);
}
}
private void eval(Vec[] valid,Vec validResp){
long[][] cm=null;
if (classification) {
int classes=ls[ls.length - 1].units;
cm=new long[classes][classes];
}
Errors e=eval(train,trainResp,10000,valid == null ? cm : null);
trainErrors=Utils.append(trainErrors,e);
if (valid != null) {
e=eval(valid,validResp,0,cm);
validErrors=Utils.append(validErrors,e);
}
NeuralNetModel model=new NeuralNetModel(destination_key,sourceKey,frame,ls);
model.training_errors=trainErrors;
model.validation_errors=validErrors;
model.confusion_matrix=cm;
UKV.put(model._selfKey,model);
}
private Errors eval(Vec[] vecs,Vec resp,long n,long[][] cm){
Errors e=NeuralNet.eval(ls,vecs,resp,n,cm);
e.training_samples=trainer.processed();
e.training_time_ms=runTimeMs();
return e;
}
}
;
trainer.start();
thread.start();
}
