def test_GBM_cancel_model_reuse(self):
    importFolderPath = 'standard'
    timeoutSecs = 500
    csvFilenameAll = [('manyfiles-nflx-gz', 'file_1.dat.gz', 378)]
    csvFilenameList = csvFilenameAll
    for (importFolderPath, csvFilename, response) in csvFilenameList:
        csvPathname = ((importFolderPath + '/') + csvFilename)
        print "FIX! is this guy getting cancelled because he's reusing a key name? but it should be okay?"
        (importResult, importPattern) = h2i.import_only(bucket='home-0xdiag-datasets', path=csvPathname, schema='local', timeoutSecs=50)
        parseResult = h2i.import_parse(bucket='home-0xdiag-datasets', path=csvPathname, schema='local', hex_key='c.hex', timeoutSecs=500, noPoll=False, doSummary=False)
        h2o.check_sandbox_for_errors()
        print "Parse result['destination_key']:", parseResult['destination_key']
        h2o.check_sandbox_for_errors()
        if DO_CLASSIFICATION:
            execExpr = ('c.hex[,%s]=c.hex[,%s]>15' % ((response + 1), (response + 1)))
            kwargs = {'str': execExpr, }
            resultExec = h2o_cmd.runExec(**kwargs)
        s = h2o_cmd.runSummary(key='c.hex', cols=response, max_ncols=1)
        ignoreIndex = [3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 16, 17, 18, 19, 20, 424, 425, 426, 540, 541, response]
        xIgnore = ','.join([('C' + str((i + 1))) for i in ignoreIndex])
        params = {'destination_key': None, 'ignored_cols_by_name': xIgnore, 'learn_rate': 0.1, 'ntrees': 2, 'max_depth': 8, 'min_rows': 1, 'response': ('C' + str((response + 1))), 'classification': (1 if DO_CLASSIFICATION else 0), 'grid_parallelism': 4, }
        kwargs = params.copy()
        timeoutSecs = 1800
        for i in range(5):
            jobids = []
            for j in range(5):
                kwargs['destination_key'] = ('GBMBad' + str(j))
                GBMFirstResult = h2o_cmd.runGBM(parseResult=parseResult, noPoll=True, **kwargs)
                jobids.append(GBMFirstResult['job_key'])
                h2o.check_sandbox_for_errors()
                modelsParams = {'key': None, 'find_compatible_frames': 0, 'score_frame': None, }
                modelsResult = h2o.nodes[0].models(timeoutSecs=10, **modelsParams)
                print 'modelsResult:', h2o.dump_json(modelsResult)
            h2o_jobs.cancelAllJobs()
            time.sleep(3)
            h2o_jobs.showAllJobs()
        if DELETE_KEYS:
            h2i.delete_keys_from_import_result(pattern=csvFilename, importResult=importResult)
