{
  int[][] _nHist=MinorityClasses.histogram(ary,_classcol);
  _gHist=MinorityClasses.globalHistogram(_nHist);
  final int num_nodes=H2O.CLOUD.size();
  final long num_chunks=ary.chunks();
  HashSet<H2ONode> nodes=new HashSet();
  for (long i=0; i < num_chunks; i++) {
    H2ONode nod=ary.getChunk(i)._h2o;
    nodes.add(nod != null ? nod : H2O.SELF);
    if (nodes.size() == num_nodes)     break;
  }
  int cloudSize=nodes.size();
  int[] nodesIdxs=new int[nodes.size()];
  int k=0;
  for (  H2ONode n : nodes)   nodesIdxs[k++]=n.index();
  Arrays.sort(nodesIdxs);
  int majority=0;
  for (  int i : _gHist)   if (i > majority)   majority=i;
  majority=Math.round((_sample * majority) / cloudSize);
  int minStrata=majority >> 9;
  _strataSamples=new int[_gHist.length];
  for (int i=0; i < _strataSamples.length; ++i) {
    int expClassNumPerNode=Math.round((_sample * _gHist[i]) / cloudSize);
    _strataSamples[i]=Math.min(_gHist[i],Math.max(minStrata,expClassNumPerNode));
  }
  if (strataSamples != null)   for (int clsIdx=0; clsIdx < strataSamples.length; clsIdx++) {
    int clsVal=strataSamples[clsIdx];
    _strataSamples[clsIdx]=Math.min(_gHist[clsIdx],clsVal);
  }
  for (  int i : nodesIdxs) {
    if (_gHist[i] < (int)(_strataSamples[i] / _sample))     Log.info(this,Sys.RANDF,"There is not enough samples of class " + i + ".");
  }
  SortedSet<Integer> uClasses=new TreeSet<Integer>();
  for (  int i : nodesIdxs) {
    for (int c=0; c < _nHist[i].length; ++c) {
      if (_nHist[i][c] < _strataSamples[c])       uClasses.add(c);
    }
  }
  if (!uClasses.isEmpty()) {
    int[] u=new int[uClasses.size()];
    int i=0;
    for (    int c : uClasses)     u[i++]=c;
    _uClasses=MinorityClasses.extractUnbalancedClasses(ary,_classcol,u);
  }
}
