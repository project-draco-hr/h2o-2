def test_GBM_with_cancels(self):
    print 'do import/parse with VA'
    importFolderPath = 'standard'
    timeoutSecs = 500
    csvFilenameAll = [('standard', 'covtype.data', 54)]
    csvFilenameList = csvFilenameAll
    for (importFolderPath, csvFilename, response) in csvFilenameList:
        csvPathname = ((importFolderPath + '/') + csvFilename)
        (importResult, importPattern) = h2i.import_only(bucket='home-0xdiag-datasets', path=csvPathname, schema='local', timeoutSecs=50)
        parseResult = h2i.import_parse(bucket='home-0xdiag-datasets', path=csvPathname, schema='local', hex_key='c.hex', timeoutSecs=500, doSummary=False)
        h2o.check_sandbox_for_errors()
        print '\nparseResult', h2o.dump_json(parseResult)
        print "Parse result['destination_key']:", parseResult['destination_key']
        h2o.check_sandbox_for_errors()
        if (importFolderPath == 'manyfiles-nflx-gz'):
            if DO_CLASSIFICATION:
                execExpr = ('c.hex[,%s]=c.hex[,%s]>15' % ((response + 1), (response + 1)))
                kwargs = {'str': execExpr, }
                resultExec = h2o_cmd.runExec(**kwargs)
            s = h2o_cmd.runSummary(key='c.hex', cols=response, max_ncols=1)
            xIgnore = []
            for i in [3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 16, 17, 18, 19, 20, 424, 425, 426, 540, 541, response]:
                xIgnore.append(('C' + str((i + 1))))
        else:
            xIgnore = 'C1'
        modelKey = 'GBMGood'
        params = {'destination_key': modelKey, 'ignored_cols_by_name': xIgnore, 'learn_rate': 0.1, 'ntrees': 2, 'max_depth': 8, 'min_rows': 1, 'response': ('C' + str((response + 1))), 'classification': (1 if DO_CLASSIFICATION else 0), 'grid_parallelism': 4, }
        kwargs = params.copy()
        timeoutSecs = 1800
        start = time.time()
        GBMFirstResult = h2o_cmd.runGBM(parseResult=parseResult, noPoll=True, **kwargs)
        print '\nGBMFirstResult:', h2o.dump_json(GBMFirstResult)
        for i in range(3):
            jobids = []
            for j in range(5):
                kwargs['destination_key'] = (('GBMBad' + str(i)) + str(j))
                GBMFirstResult = h2o_cmd.runGBM(parseResult=parseResult, noPoll=True, **kwargs)
                jobids.append(GBMFirstResult['job_key'])
            for j in jobids:
                h2o.nodes[0].jobs_cancel(key=j)
        h2o_jobs.pollWaitJobs(pattern='GBMGood', timeoutSecs=300, pollTimeoutSecs=10, retryDelaySecs=5)
        elapsed = (time.time() - start)
        print 'GBM training completed in', elapsed, 'seconds.'
        gbmTrainView = h2o_cmd.runGBMView(model_key=modelKey)
        errsLast = gbmTrainView['gbm_model']['errs'][(-1)]
        print "GBM 'errsLast'", errsLast
        if DO_CLASSIFICATION:
            cm = gbmTrainView['gbm_model']['cms'][(-1)]['_arr']
            pctWrongTrain = h2o_gbm.pp_cm_summary(cm)
            print 'Last line of this cm might be NAs, not CM'
            print '\nTrain\n==========\n'
            print h2o_gbm.pp_cm(cm)
        else:
            print 'GBMTrainView:', h2o.dump_json(gbmTrainView['gbm_model']['errs'])
        h2o.check_sandbox_for_errors()
        if DELETE_KEYS:
            h2i.delete_keys_from_import_result(pattern=csvFilename, importResult=importResult)
