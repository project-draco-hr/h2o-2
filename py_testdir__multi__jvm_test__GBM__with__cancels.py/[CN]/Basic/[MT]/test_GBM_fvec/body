def test_GBM_fvec(self):
    print 'Sets h2o.beta_features like -bf at command line'
    print 'this will redirect import and parse to the 2 variants'
    h2o.beta_features = True
    importFolderPath = 'standard'
    timeoutSecs = 500
    csvFilenameAll = [('manyfiles-nflx-gz', 'file_1.dat.gz', 378)]
    csvFilenameList = csvFilenameAll
    for (importFolderPath, csvFilename, response) in csvFilenameList:
        csvPathname = ((importFolderPath + '/') + csvFilename)
        (importResult, importPattern) = h2i.import_only(bucket='home-0xdiag-datasets', path=csvPathname, schema='local', timeoutSecs=50)
        parseResult = h2i.import_parse(bucket='home-0xdiag-datasets', path=csvPathname, schema='local', hex_key='c.hex', timeoutSecs=500, noPoll=False, doSummary=False)
        h2o.check_sandbox_for_errors()
        if h2o.beta_features:
            parseResult = {'destination_key': 'c.hex', }
        print '\nparseResult', h2o.dump_json(parseResult)
        print "Parse result['destination_key']:", parseResult['destination_key']
        h2o.check_sandbox_for_errors()
        if (importFolderPath == 'manyfiles-nflx-gz'):
            if DO_CLASSIFICATION:
                execExpr = ('c.hex[,%s]=c.hex[,%s]>15' % (response, response))
                kwargs = {'str': execExpr, }
                resultExec = h2o_cmd.runExec(**kwargs)
            s = h2o_cmd.runSummary(key='c.hex', cols=response, max_ncols=1)
            x = range(542)
            xIgnore = []
            for i in [3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 16, 17, 18, 19, 20, 424, 425, 426, 540, 541, response]:
                if (i not in x):
                    print 'x:', x
                    print 'missing?', i
                x.remove(i)
                xIgnore.append(i)
            x = ','.join(map(str, x))

            def colIt(x):
                return ('C' + str(x))
            xIgnore = ','.join(map(colIt, xIgnore))
        else:
            xIgnore = 0
        modelKey = 'GBMGood'
        params = {'destination_key': modelKey, 'ignored_cols_by_name': xIgnore, 'learn_rate': 0.1, 'ntrees': 2, 'max_depth': 8, 'min_rows': 1, 'response': ('C' + str(response)), 'classification': (1 if DO_CLASSIFICATION else 0), }
        kwargs = params.copy()
        timeoutSecs = 1800
        start = time.time()
        GBMFirstResult = h2o_cmd.runGBM(parseResult=parseResult, noPoll=True, **kwargs)
        print '\nGBMFirstResult:', h2o.dump_json(GBMFirstResult)
        for i in range(20):
            jobids = []
            for j in range(5):
                kwargs['destination_key'] = ('GBMBad' + str(j))
                GBMFirstResult = h2o_cmd.runGBM(parseResult=parseResult, noPoll=True, **kwargs)
                jobids[j] = GBMFirstResult['job_key']
            for j in jobids:
                h2o.nodes[0].jobs_cancel(key=j)
        h2o_jobs.pollWaitJobs(pattern='GBMGood', timeoutSecs=300, pollTimeoutSecs=10, retryDelaySecs=5)
        elapsed = (time.time() - start)
        print 'GBM training completed in', elapsed, 'seconds.'
        gbmTrainView = h2o_cmd.runGBMView(model_key=modelKey)
        errsLast = gbmTrainView['gbm_model']['errs'][(-1)]
        print "GBM 'errsLast'", errsLast
        if DO_CLASSIFICATION:
            cm = gbmTrainView['gbm_model']['cm']
            pctWrongTrain = h2o_gbm.pp_cm_summary(cm)
            print 'Last line of this cm might be NAs, not CM'
            print '\nTrain\n==========\n'
            print h2o_gbm.pp_cm(cm)
        else:
            print 'GBMTrainView:', h2o.dump_json(gbmTrainView['gbm_model']['errs'])
        h2o.check_sandbox_for_errors()
        if DELETE_KEYS:
            h2i.delete_keys_from_import_result(pattern=csvFilename, importResult=importResult)
