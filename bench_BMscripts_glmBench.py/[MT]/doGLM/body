def doGLM(f, folderPath, family, link, lambda_, alpha, nfolds, y, x, testFilehex, row):
    debug = False
    bench = 'bench'
    if debug:
        print 'DOING GLM DEBUG'
        bench = 'bench/debug'
    date = '-'.join([str(z) for z in list(time.localtime())][0:3])
    overallWallStart = time.time()
    pre = ''
    if debug:
        pre = 'DEBUG'
    glmbenchcsv = (((('benchmarks/' + build) + '/') + pre) + 'glmbench.csv')
    if (not os.path.exists(glmbenchcsv)):
        output = open(glmbenchcsv, 'w')
        output.write((','.join(csv_header) + '\n'))
    else:
        output = open(glmbenchcsv, 'a')
    csvWrt = csv.DictWriter(output, fieldnames=csv_header, restval=None, dialect='excel', extrasaction='ignore', delimiter=',')
    try:
        java_heap_GB = h2o.nodes[0].java_heap_GB
        importFolderPath = ((bench + '/') + folderPath)
        if (f in ['AirlinesTrain1x', 'AllBedroomsTrain1x', 'AllBedroomsTrain10x', 'AllBedroomsTrain100x']):
            csvPathname = (((importFolderPath + '/') + f) + '.csv')
        else:
            csvPathname = (((importFolderPath + '/') + f) + '/*linked*')
        hex_key = (f + '.hex')
        hK = (folderPath + 'Header.csv')
        headerPathname = ((importFolderPath + '/') + hK)
        h2i.import_only(bucket='home-0xdiag-datasets', path=headerPathname)
        headerKey = h2i.find_key(hK)
        trainParseWallStart = time.time()
        parseResult = h2i.import_parse(bucket='home-0xdiag-datasets', path=csvPathname, schema='local', hex_key=hex_key, header=1, header_from_file=headerKey, separator=44, timeoutSecs=7200, retryDelaySecs=5, pollTimeoutSecs=7200, doSummary=False)
        parseWallTime = (time.time() - trainParseWallStart)
        print 'Parsing training file took ', parseWallTime, ' seconds.'
        inspect_train = h2o.nodes[0].inspect(parseResult['destination_key'], timeoutSecs=7200)
        inspect_test = h2o.nodes[0].inspect(testFilehex, timeoutSecs=7200)
        nMachines = (1 if (len(h2o_hosts.hosts) is 0) else len(h2o_hosts.hosts))
        row.update({'h2o_build': build, 'nMachines': nMachines, 'nJVMs': len(h2o.nodes), 'Xmx/JVM': java_heap_GB, 'dataset': f, 'nTrainRows': inspect_train['num_rows'], 'nTestRows': inspect_test['num_rows'], 'nCols': inspect_train['num_cols'], 'trainParseWallTime': parseWallTime, 'nfolds': nfolds, 'family': family, })
        params = {'y': y, 'x': x, 'family': family, 'link': link, 'lambda': lambda_, 'alpha': alpha, 'n_folds': nfolds, 'case_mode': 'n/a', 'destination_key': (('GLM(' + f) + ')'), 'expert_settings': 0, }
        kwargs = params.copy()
        glmStart = time.time()
        glm = h2o_cmd.runGLM(parseResult=parseResult, timeoutSecs=7200, **kwargs)
        glmTime = (time.time() - glmStart)
        row.update({'glmBuildTime': glmTime, })
        glmScoreStart = time.time()
        glmScore = h2o_cmd.runGLMScore(key=testFilehex, model_key=params['destination_key'], timeoutSecs=1800)
        scoreTime = (time.time() - glmScoreStart)
        cmd = (('bash startloggers.sh ' + json) + ' stop_')
        os.system(cmd)
        if (family == 'binomial'):
            row.update({'scoreTime': scoreTime, 'AUC': glmScore['validation']['auc'], 'AIC': glmScore['validation']['aic'], 'error': glmScore['validation']['err'], })
        else:
            row.update({'scoreTime': scoreTime, 'AIC': glmScore['validation']['aic'], 'AUC': 'NA', 'error': glmScore['validation']['err'], })
        csvWrt.writerow(row)
    finally:
        output.close()
