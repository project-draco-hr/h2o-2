def test_hdfs2_3(self):
    print '\nLoad a list of files from HDFS, parse and do 1 RF tree'
    print '\nYou can try running as hduser/hduser if fail'
    csvFilenameAll = ['covtype.data', 'TEST-poker1000.csv', 'leads.csv', 'and-testing.data', 'arcene2_train.both', 'arcene_train.both', 'covtype.4x.shuffle.data', 'covtype4x.shuffle.data', 'covtype.13x.data', 'covtype.13x.shuffle.data', 'prostate_long_1G.csv', 'hhp.unbalanced.012.1x11.data.gz', 'hhp.unbalanced.012.data.gz', 'hhp.unbalanced.data.gz', 'hhp2.os.noisy.0_1.data', 'hhp2.os.noisy.9_4.data', 'hhp_9_14_12.data']
    if (1 == 0):
        csvFilenameList = random.sample(csvFilenameAll, 8)
    else:
        csvFilenameList = csvFilenameAll
    timeoutSecs = 200
    importFolderPath = 'datasets'
    for csvFilename in csvFilenameList:
        print 'Loading', csvFilename, 'from HDFS'
        csvPathname = ((importFolderPath + '/') + csvFilename)
        start = time.time()
        parseResult = h2i.import_parse(path=csvPathname, schema='hdfs', timeoutSecs=1000, header=0, doSummary=DO_SUMMARY, blocking=1)
        print 'parse result:', parseResult['destination_key'], 'took', (time.time() - start), 'secs'
        inspect = h2o_cmd.runInspect(key=parseResult['destination_key'])
        numRows = inspect['numRows']
        numCols = inspect['numCols']
        print ('\n' + csvPathname), '    numRows:', '{:,}'.format(numRows), '    numCols:', '{:,}'.format(numCols)
        start = time.time()
        modelKey = 'rfmodel.hex'
        kwargs = {}
        RFview = h2o_cmd.runRF(trees=1, parseResult=parseResult, timeoutSecs=2000, retryDelaySecs=0.5, destination_key=modelKey, **kwargs)
