def test_parse_airline_multi_hdfs_many(self):
    h2o.beta_features = True
    csvFilename = 'hex_10'
    csvFilePattern = '*'
    for tryHeap in [24]:
        print '\n', tryHeap, 'GB heap, 1 jvm per host, import mr-0x6 hdfs, then parse'
        localhost = h2o.decide_if_localhost()
        if localhost:
            h2o.build_cloud(java_heap_GB=tryHeap, random_udp_drop=RANDOM_UDP_DROP, use_hdfs=True, hdfs_name_node=NAME_NODE, hdfs_version=VERSION)
        else:
            h2o_hosts.build_cloud_with_hosts(java_heap_GB=tryHeap, random_udp_drop=RANDOM_UDP_DROP, disable_assertions=False, use_hdfs=True, hdfs_name_node=NAME_NODE, hdfs_version=VERSION)
        timeoutSecs = 500
        importFolderPath = 'datasets/airlines_multi'
        csvPathname = ((importFolderPath + '/') + csvFilePattern)
        parseResult = h2i.import_only(path=csvPathname, schema='hdfs', timeoutSecs=timeoutSecs, retryDelaySecs=10, pollTimeoutSecs=60)
        for trial in range(TRIAL_MAX):
            csvFilePattern = ('*%s.csv' % trial)
            hex_key = (((csvFilename + '_') + str(trial)) + '.hex')
            csvPathname = ((importFolderPath + '/') + csvFilePattern)
            start = time.time()
            print 'Drat. the source file is locked if we noPoll. Would have to increment across the individual files?'
            print "Drat. We can't re-import the folder, if there's a parse using one of the source files?"
            parseResult = h2i.parse_only(pattern=csvFilePattern, hex_key=hex_key, noPoll=True, delete_on_done=0, timeoutSecs=timeoutSecs, retryDelaySecs=10, pollTimeoutSecs=60)
            elapsed = (time.time() - start)
            print 'parse result:', parseResult['destination_key']
            print 'Parse #', trial, 'completed in', ('%6.2f' % elapsed), 'seconds.', ('%d pct. of timeout' % ((elapsed * 100) / timeoutSecs))
            h2o_cmd.runStoreView()
        h2j.pollWaitJobs(timeoutSecs=300, pollTimeoutSecs=30)
        h2o.tear_down_cloud()
        time.sleep(5)
