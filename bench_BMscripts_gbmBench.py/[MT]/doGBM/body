def doGBM(fs, folderPath, ignored_cols, classification, testFilehex, ntrees, depth, minrows, nbins, learnRate, response, row):
    debug = False
    h2o.beta_features = True
    bench = 'bench'
    if debug:
        print 'Doing GBM DEBUG'
        bench = 'bench/debug'
    date = '-'.join([str(x) for x in list(time.localtime())][0:3])
    for f in fs['train']:
        overallWallStart = time.time()
        pre = ''
        if debug:
            pre = 'DEBUG'
        gbmbenchcsv = (((((('benchmarks/' + build) + '/') + date) + '/') + pre) + 'gbmbench.csv')
        if (not os.path.exists(gbmbenchcsv)):
            output = open(gbmbenchcsv, 'w')
            output.write((','.join(csv_header) + '\n'))
        else:
            output = open(gbmbenchcsv, 'a')
        csvWrt = csv.DictWriter(output, fieldnames=csv_header, restval=None, dialect='excel', extrasaction='ignore', delimiter=',')
        try:
            java_heap_GB = h2o.nodes[0].java_heap_GB
            importFolderPath = ((bench + '/') + folderPath)
            if (f in ['AirlinesTrain1x', 'AllBedroomsTrain1x', 'AllBedroomsTrain10x', 'AllBedroomsTrain100x', 'CovTypeTrain1x', 'CovTypeTrain10x', 'CovTypeTrain100x']):
                csvPathname = (((importFolderPath + '/') + f) + '.csv')
            else:
                csvPathname = (((importFolderPath + '/') + f) + '/*linked*')
            hex_key = (f + '.hex')
            hK = (folderPath + 'Header.csv')
            headerPathname = ((importFolderPath + '/') + hK)
            h2i.import_only(bucket='home-0xdiag-datasets', path=headerPathname)
            headerKey = h2i.find_key(hK)
            trainParseWallStart = time.time()
            if (f in ['AirlinesTrain10x', 'AirlinesTrain100x']):
                h2o.beta_features = False
            parseResult = h2i.import_parse(bucket='home-0xdiag-datasets', path=csvPathname, schema='local', hex_key=hex_key, header=1, header_from_file=headerKey, separator=44, timeoutSecs=7200, retryDelaySecs=5, pollTimeoutSecs=7200, noPoll=True, doSummary=False)
            h2o_jobs.pollWaitJobs(timeoutSecs=7200, pollTimeoutSecs=7200, retryDelaySecs=5)
            parseWallTime = (time.time() - trainParseWallStart)
            print 'Parsing training file took ', parseWallTime, ' seconds.'
            inspect_train = h2o.nodes[0].inspect(hex_key, timeoutSecs=7200)
            inspect_test = h2o.nodes[0].inspect(testFilehex, timeoutSecs=7200)
            h2o.beta_features = True
            nMachines = (1 if (len(h2o_hosts.hosts) is 0) else len(h2o_hosts.hosts))
            row.update({'h2o_build': build, 'nMachines': nMachines, 'nJVMs': len(h2o.nodes), 'Xmx/JVM': java_heap_GB, 'dataset': f, 'nTrainRows': inspect_train['num_rows'], 'nTestRows': inspect_test['num_rows'], 'nCols': inspect_train['num_cols'], 'trainParseWallTime': parseWallTime, 'classification': classification, })
            params = {'destination_key': (('GBM(' + f) + ')'), 'response': response, 'ignored_cols_by_name': ignored_cols, 'classification': classification, 'validation': testFilehex, 'ntrees': ntrees, 'max_depth': depth, 'min_rows': minrows, 'nbins': nbins, 'learn_rate': learnRate, }
            parseResult = {'destination_key': hex_key, }
            kwargs = params.copy()
            gbmStart = time.time()
            gbm = h2o_cmd.runGBM(parseResult=parseResult, noPoll=True, timeoutSecs=4800, **kwargs)
            h2o_jobs.pollWaitJobs(timeoutSecs=7200, pollTimeoutSecs=120, retryDelaySecs=5)
            gbmTime = (time.time() - gbmStart)
            row.update({'gbmBuildTime': gbmTime, })
            gbmTrainView = h2o_cmd.runGBMView(model_key=(('GBM(' + f) + ')'))
            if classification:
                cm = gbmTrainView['gbm_model']['cm']
                err = ((1.0 * (cm[0][1] + cm[1][0])) / (((cm[0][0] + cm[0][1]) + cm[1][0]) + cm[1][1]))
            else:
                err = gbmTrainView['gbm_model']['errs'][(-1)]
            row.update({'Error': err, })
            csvWrt.writerow(row)
        finally:
            output.close()
