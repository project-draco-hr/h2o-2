def doGBM(f, folderPath, ignored_cols, classification, testFilehex, ntrees, depth, minrows, nbins, learnRate, response, row):
    debug = False
    bench = 'bench'
    if debug:
        print 'Doing GBM DEBUG'
        bench = 'bench/debug'
    date = '-'.join([str(x) for x in list(time.localtime())][0:3])
    overallWallStart = time.time()
    pre = ''
    if debug:
        pre = 'DEBUG'
    gbmbenchcsv = (((((('benchmarks/' + build) + '/') + date) + '/') + pre) + 'gbmbench.csv')
    if (not os.path.exists(gbmbenchcsv)):
        output = open(gbmbenchcsv, 'w')
        output.write((','.join(csv_header) + '\n'))
    else:
        output = open(gbmbenchcsv, 'a')
    csvWrt = csv.DictWriter(output, fieldnames=csv_header, restval=None, dialect='excel', extrasaction='ignore', delimiter=',')
    try:
        java_heap_GB = h2o.nodes[0].java_heap_GB
        importFolderPath = ((bench + '/') + folderPath)
        if (f in ['AirlinesTrain1x', 'AllBedroomsTrain1x', 'AllBedroomsTrain10x', 'AllBedroomsTrain100x', 'CovTypeTrain1x', 'CovTypeTrain10x', 'CovTypeTrain100x']):
            csvPathname = (((importFolderPath + '/') + f) + '.csv')
        else:
            csvPathname = (((importFolderPath + '/') + f) + '/*linked*')
        hex_key = (f + '.hex')
        hK = (folderPath + 'Header.csv')
        headerPathname = ((importFolderPath + '/') + hK)
        h2i.import_only(bucket='home-0xdiag-datasets', path=headerPathname)
        headerKey = h2i.find_key(hK)
        trainParseWallStart = time.time()
        h2o.beta_features = False
        if (f in ['AirlinesTrain10x', 'AirlinesTrain100x']):
            h2o.beta_features = False
        parseResult = h2i.import_parse(bucket='home-0xdiag-datasets', path=csvPathname, schema='local', hex_key=hex_key, header=1, header_from_file=headerKey, separator=44, timeoutSecs=16000, retryDelaySecs=5, pollTimeoutSecs=16000, noPoll=True, doSummary=False)
        h2o_jobs.pollWaitJobs(timeoutSecs=16000, pollTimeoutSecs=16000, retryDelaySecs=5)
        parseWallTime = (time.time() - trainParseWallStart)
        print 'Parsing training file took ', parseWallTime, ' seconds.'
        h2o.beta_features = False
        inspect_train = h2o.nodes[0].inspect(hex_key, timeoutSecs=16000)
        inspect_test = h2o.nodes[0].inspect(testFilehex, timeoutSecs=16000)
        h2o.beta_features = True
        nMachines = (1 if (len(h2o_hosts.hosts) is 0) else len(h2o_hosts.hosts))
        row.update({'h2o_build': build, 'nMachines': nMachines, 'nJVMs': len(h2o.nodes), 'Xmx/JVM': java_heap_GB, 'dataset': f, 'nTrainRows': inspect_train['num_rows'], 'nTestRows': inspect_test['num_rows'], 'nCols': inspect_train['num_cols'], 'trainParseWallTime': parseWallTime, 'nTrees': ntrees, 'minRows': minrows, 'maxDepth': depth, 'learnRate': learnRate, 'classification': classification, })
        params = {'destination_key': (('GBM(' + f) + ')'), 'response': response, 'ignored_cols_by_name': ignored_cols, 'classification': classification, 'validation': testFilehex, 'ntrees': ntrees, 'max_depth': depth, 'min_rows': minrows, 'nbins': nbins, 'learn_rate': learnRate, }
        parseResult = {'destination_key': hex_key, }
        kwargs = params.copy()
        gbmStart = time.time()
        gbm = h2o_cmd.runGBM(parseResult=parseResult, noPoll=True, timeoutSecs=4800, **kwargs)
        h2o_jobs.pollWaitJobs(timeoutSecs=16000, pollTimeoutSecs=120, retryDelaySecs=5)
        gbmTime = (time.time() - gbmStart)
        row.update({'gbmBuildTime': gbmTime, })
        gbmTrainView = h2o_cmd.runGBMView(model_key=(('GBM(' + f) + ')'))
        if classification:
            cm = gbmTrainView['gbm_model']['cm']
            err = ((1.0 * (cm[0][1] + cm[1][0])) / (((cm[0][0] + cm[0][1]) + cm[1][0]) + cm[1][1]))
        else:
            err = gbmTrainView['gbm_model']['errs'][(-1)]
        row.update({'Error': err, })
        csvWrt.writerow(row)
    finally:
        output.close()
