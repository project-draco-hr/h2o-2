{
  _trainers=new Base[cores];
  _threads=new Thread[_trainers.length];
  _stepsPerThread=steps / _threads.length;
  _resume=new CyclicBarrier(_threads.length + 1);
  for (int t=0; t < _trainers.length; t++) {
    Layer[] clones=new Layer[ls.length];
    for (int y=0; y < clones.length; y++)     clones[y]=ls[y].clone();
    for (int y=0; y < clones.length; y++)     clones[y].init(clones,y,false,0);
    final Input input=(Input)clones[0];
    input._pos=input._len * t / _trainers.length;
    _trainers[t]=new Base(clones);
    final Base trainer=_trainers[t];
    _threads[t]=new Thread("H2O Trainer " + t){
      @Override public void run(){
        for (int i=0; _stepsPerThread == 0 || i < _stepsPerThread; i++) {
          CyclicBarrier b=_suspend;
          if (b == DONE)           break;
          if (b != null) {
            try {
              b.await();
              _resume.await();
            }
 catch (            Exception e) {
              throw new RuntimeException(e);
            }
          }
          trainer.step();
          input.move();
          _items.incrementAndGet();
        }
      }
    }
;
  }
  Log.info("Started " + _trainers.length + " neural network trainers");
}
