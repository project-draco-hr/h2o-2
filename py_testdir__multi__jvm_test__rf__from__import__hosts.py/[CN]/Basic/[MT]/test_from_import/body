def test_from_import(self):
    importFolderPath = '/home/0xdiag/datasets'
    h2i.setupImportFolder(None, importFolderPath)
    timeoutSecs = 500
    csvFilenameAll = [('manyfiles-nflx-gz/file_1.dat.gz', 'file_1.dat.gz'), ('covtype.data', 'covtype.data'), ('covtype20x.data', 'covtype20x.data')]
    csvFilenameList = csvFilenameAll
    h2b.browseTheCloud()
    for (csvFilepattern, csvFilename) in csvFilenameList:
        start = time.time()
        parseKey = h2i.parseImportFolderFile(None, csvFilepattern, importFolderPath, key2=csvFilename, timeoutSecs=500)
        elapsed = (start - time.time())
        print 'parse end on ', csvFilepattern, 'took', elapsed, 'seconds.', ('%d pct. of timeout' % ((elapsed / timeoutSecs) * 100))
        print csvFilepattern, 'parse time:', parseKey['response']['time']
        print "Parse result['destination_key']:", parseKey['destination_key']
        inspect = h2o_cmd.runInspect(key=parseKey['destination_key'])
        origKey = parseKey['destination_key']
        execExpr = (('a = randomFilter(' + origKey) + ',200,12345678)')
        h2e.exec_expr(h2o.nodes[0], execExpr, 'a', timeoutSecs=30)
        newParseKey = {'destination_key': 'a', }
        print ('\n' + csvFilepattern)
        start = time.time()
        RFview = h2o_cmd.runRFOnly(trees=1, depth=25, parseKey=newParseKey, timeoutSecs=timeoutSecs)
        h2b.browseJsonHistoryAsUrlLastMatch('RFView')
        time.sleep(10)
        sys.stdout.write('.')
        sys.stdout.flush()
