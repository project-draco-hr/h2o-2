def test_parse_summary_manyfiles_s3_fvec(self):
    h2o.beta_features = True
    csvDirlist = [('manyfiles-nflx-gz', 600)]
    trial = 0
    for (csvDirname, timeoutSecs) in csvDirlist:
        csvPathname = (csvDirname + '/file_[2][0-9][0-9].dat.gz')
        (importHDFSResult, importPattern) = h2i.import_only(bucket='home-0xdiag-datasets', path=csvPathname, schema='s3', timeoutSecs=timeoutSecs)
        print '\nTrying StoreView after the import hdfs'
        h2o_cmd.runStoreView(timeoutSecs=120)
        trialStart = time.time()
        hex_key = (((csvDirname + '_') + str(trial)) + '.hex')
        start = time.time()
        parseResult = h2i.import_parse(bucket='home-0xdiag-datasets', path=csvPathname, schema='s3', hex_key=hex_key, timeoutSecs=timeoutSecs, retryDelaySecs=10, pollTimeoutSecs=120)
        elapsed = (time.time() - start)
        print 'parse end on ', parseResult['destination_key'], 'took', elapsed, 'seconds', ('%d pct. of timeout' % ((elapsed * 100) / timeoutSecs))
        start = time.time()
        inspect = h2o_cmd.runInspect(None, parseResult['destination_key'], timeoutSecs=360)
        print 'Inspect:', parseResult['destination_key'], 'took', (time.time() - start), 'seconds'
        h2o_cmd.infoFromInspect(inspect, csvPathname)
        goodX = h2o_glm.goodXFromColumnInfo(y=54, key=parseResult['destination_key'], timeoutSecs=300)
        summaryResult = h2o_cmd.runSummary(key=hex_key, timeoutSecs=360)
        h2o_cmd.infoFromSummary(summaryResult)
        print '\nTrying StoreView after the parse'
        h2o_cmd.runStoreView(timeoutSecs=120)
        print 'Trial #', trial, 'completed in', (time.time() - trialStart), 'seconds.'
        trial += 1
