def test_GLM_big1_nopoll(self):
    csvPathname = h2o.find_file('smalldata/hhp_107_01.data.gz')
    print ('\n' + csvPathname)
    y = '106'
    x = ''
    parseKey = h2o_cmd.parseFile(csvPathname=csvPathname, timeoutSecs=15)
    glmInitial = []
    for jobDispatch in range(40):
        start = time.time()
        kwargs = {'x': x, 'y': y, 'n_folds': 1, }
        glm = h2o_cmd.runGLMOnly(parseKey=parseKey, timeoutSecs=300, noPoll=True, **kwargs)
        glmInitial.append(glm)
        print 'glm job dispatch end on ', csvPathname, 'took', (time.time() - start), 'seconds'
        print '\njobDispatch #', jobDispatch
    anyBusy = True
    waitLoop = 0
    while anyBusy:
        anyBusy = False
        a = h2o.nodes[0].jobs_admin()
        jobs = a['jobs']
        GLMModelKeys = []
        for j in jobs:
            if ('GLMModel' in j['destination_key']):
                GLMModelKeys.append(j['destination_key'])
            if (j['end_time'] == ''):
                anyBusy = True
                print 'Loop', waitLoop, 'Not done - ', 'destination_key:', j['destination_key'], 'progress:', j['progress'], 'cancelled:', j['cancelled'], 'end_time:', j['end_time']
        print '\n'
        h2b.browseJsonHistoryAsUrlLastMatch('Jobs')
        if (anyBusy and (waitLoop > 20)):
            print h2o.dump_json(jobs)
            raise Exception("Some queued jobs haven't completed after", waitLoop, 'wait loops')
        time.sleep(5)
        waitLoop += 1
    for glm in glmInitial:
        print 'Checking completed job, with no polling:', glm
        a = h2o.nodes[0].poll_url(glm['response'], noPoll=True)
        h2o_glm.simpleCheckGLM(self, a, 57, **kwargs)
