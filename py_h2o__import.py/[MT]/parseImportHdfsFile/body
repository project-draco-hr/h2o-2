def parseImportHdfsFile(node=None, csvFilename=None, path=None, key2=None, schema='hdfs', timeoutSecs=3600, retryDelaySecs=2, initialDelaySecs=1, pollTimeoutSecs=180, noise=None, benchmarkLogging=None, noPoll=False, **kwargs):
    if (not csvFilename):
        raise Exception('No csvFilename parameter in parseImportHdfsFile')
    if (not node):
        node = h2o.nodes[0]
    print 'parseImportHdfsFile schema:', schema
    if (schema == 'maprfs'):
        hdfsPrefix = (schema + ':')
    elif (schema == 's3n'):
        hdfsPrefix = (schema + ':/')
    elif (schema == 'hdfs'):
        hdfsPrefix = ((schema + '://') + node.hdfs_name_node)
    else:
        raise Exception((('Uknown schema: ' + schema) + ' in parseImportHdfsFile'))
    if (path is None):
        URI = (hdfsPrefix + '/datasets')
    else:
        URI = (hdfsPrefix + path)
    hdfsKey = ((URI + '/') + csvFilename)
    print 'parseImportHdfsFile hdfsKey:', hdfsKey
    inspect = h2o_cmd.runInspect(key=hdfsKey)
    print 'parseImportHdfsFile inspect of source:', inspect
    if (key2 is None):
        myKey2 = (csvFilename + '.hex')
    else:
        myKey2 = key2
    parseKey = node.parse(hdfsKey, myKey2, timeoutSecs, retryDelaySecs, initialDelaySecs, pollTimeoutSecs, noise, benchmarkLogging, noPoll, **kwargs)
    parseKey['source_key'] = hdfsKey
    print 'parseImportHdfsFile:', parseKey
    return parseKey
