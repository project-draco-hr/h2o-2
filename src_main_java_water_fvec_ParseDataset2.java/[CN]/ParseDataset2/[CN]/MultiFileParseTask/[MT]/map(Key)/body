{
  ByteVec vec=(ByteVec)getVec(key);
  byte[] bits=vec.elem2BV(0)._mem;
  final int chunkStartIdx=_fileChunkOffsets.get(key)._val;
  Compression cpr=Utils.guessCompressionMethod(bits);
  CustomParser.ParserSetup localSetup=ParseDataset.guessSetup(Utils.unzipBytes(bits,cpr),_setup,false)._setup;
  if (!_setup.isCompatible(localSetup)) {
    _parserr="Conflicting file layouts, expecting: " + _setup + " but found "+ localSetup;
    return;
  }
  boolean has_hdr=_setup._header && localSetup._header;
  if (has_hdr) {
    for (int i=0; i < localSetup._columnNames.length; ++i)     has_hdr=localSetup._columnNames[i].equalsIgnoreCase(_setup._columnNames[i]);
    if (!has_hdr)     localSetup=new CustomParser.ParserSetup(ParserType.CSV,localSetup._separator,false);
  }
  final int ncols=_setup._ncols;
  try {
switch (cpr) {
case NONE:
      if (localSetup._pType.parallelParseSupported)       _dout=new DParse(_vg,localSetup,_vecIdStart,chunkStartIdx).doAll(vec)._dout;
 else {
        ParseProgressMonitor pmon=new ParseProgressMonitor(_progress);
        _dout=streamParse(vec.openStream(pmon),localSetup,_vecIdStart,chunkStartIdx,pmon);
      }
    break;
case ZIP:
{
    ParseProgressMonitor pmon=new ParseProgressMonitor(_progress);
    ZipInputStream zis=new ZipInputStream(vec.openStream(pmon));
    ZipEntry ze=zis.getNextEntry();
    if (ze != null && !ze.isDirectory())     _dout=streamParse(zis,localSetup,_vecIdStart,chunkStartIdx,pmon);
 else     zis.close();
    break;
  }
case GZIP:
ParseProgressMonitor pmon=new ParseProgressMonitor(_progress);
_dout=streamParse(new GZIPInputStream(vec.openStream(pmon)),localSetup,_vecIdStart,chunkStartIdx,pmon);
break;
}
}
 catch (IOException ioe) {
throw new RuntimeException(ioe);
}
}
