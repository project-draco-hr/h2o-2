{
  ByteVec vec=(ByteVec)getVec(key);
  byte[] bits=vec.elem2BV(0)._mem;
  Compression cpr=guessCompressionMethod(vec);
  CustomParser.ParserSetup localSetup=ParseDataset.guessSetup(Utils.unzipBytes(bits,cpr),_setup,true);
  if (!_setup.isCompatible(localSetup)) {
    _parserr="Conflicting file layouts, expecting: " + _setup + " but found "+ localSetup;
    return;
  }
  boolean has_hdr=_setup._header && localSetup._header;
  if (has_hdr) {
    for (int i=0; i < localSetup._columnNames.length; ++i)     has_hdr=localSetup._columnNames[i].equalsIgnoreCase(_setup._columnNames[i]);
    if (!has_hdr)     localSetup=new CustomParser.ParserSetup(ParserType.CSV,localSetup._separator,false,localSetup._data);
  }
  final int ncols=_setup._ncols;
  _vecs=new Vec[ncols];
  Key[] keys=vec.group().addVecs(ncols);
  for (int i=0; i < ncols; i++)   _vecs[i]=new AppendableVec(keys[i]);
  try {
switch (cpr) {
case NONE:
      if (!localSetup._pType.parallelParseSupported) {
        streamParse(vec.openStream(_progress),localSetup);
      }
 else       if (localSetup._pType == ParserType.CSV) {
        Vec bvs[]=Arrays.copyOf(_vecs,_vecs.length + 1,Vec[].class);
        bvs[bvs.length - 1]=vec;
        DParse dp=new DParse(localSetup).doAll(bvs);
        for (int i=0; i < _vecs.length; i++)         _vecs[i]=dp.vecs(i);
      }
 else {
        SVMLightDParse sdp=new SVMLightDParse().doAll(vec);
        Vec[] newVecs=sdp._dout.closeVecs(_fs);
        new SVFTask(new Frame(null,newVecs)).invokeOnAllNodes();
        _vecs=newVecs;
      }
    break;
case ZIP:
{
    ZipInputStream zis=new ZipInputStream(vec.openStream(_progress));
    ZipEntry ze=zis.getNextEntry();
    if (ze != null && !ze.isDirectory())     streamParse(zis,localSetup);
 else     zis.close();
    break;
  }
case GZIP:
streamParse(new GZIPInputStream(vec.openStream(_progress)),localSetup);
break;
}
}
 catch (IOException ioe) {
_parserr=ioe.toString();
return;
}
}
