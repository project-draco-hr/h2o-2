def test_rf_log_fvec(self):
    h2o.beta_features = True
    SYNDATASETS_DIR = h2o.make_syn_dir()
    tryList = [(10000, 100, 'cA', 300)]
    for (rowCount, colCount, hex_key, timeoutSecs) in tryList:
        SEEDPERFILE = random.randint(0, sys.maxint)
        csvFilename = (((('syn_test_' + str(rowCount)) + 'x') + str(colCount)) + '.csv')
        csvPathname = ((SYNDATASETS_DIR + '/') + csvFilename)
        print 'Creating random', csvPathname
        write_syn_dataset(csvPathname, rowCount, colCount, SEEDPERFILE)
        testParseResult = h2i.import_parse(path=csvPathname, hex_key=hex_key, schema='put', timeoutSecs=10)
        print "Test Parse result['destination_key']:", testParseResult['destination_key']
        dataKeyTest = testParseResult['destination_key']
        csvFilename = (((('syn_train_' + str(rowCount)) + 'x') + str(colCount)) + '.csv')
        csvPathname = ((SYNDATASETS_DIR + '/') + csvFilename)
        print 'Creating random', csvPathname
        write_syn_dataset(csvPathname, rowCount, colCount, SEEDPERFILE)
        trainParseResult = h2i.import_parse(path=csvPathname, hex_key=hex_key, schema='put', timeoutSecs=10)
        print "Train Parse result['destination_key']:", trainParseResult['destination_key']
        dataKeyTrain = trainParseResult['destination_key']
        kwargs = paramDict.copy()
        timeoutSecs = (30 + (kwargs['ntrees'] * 20))
        start = time.time()
        kwargs['response'] = ('C' + str((colCount + 1)))
        rfv = h2o_cmd.runRF(parseResult=trainParseResult, timeoutSecs=timeoutSecs, **kwargs)
        elapsed = (time.time() - start)
        print 'RF end on ', csvPathname, 'took', elapsed, 'seconds.', ('%d pct. of timeout' % ((elapsed / timeoutSecs) * 100))
        rf_model = rfv['drf_model']
        used_trees = rf_model['N']
        data_key = rf_model['_dataKey']
        model_key = rf_model['_key']
        (classification_error, classErrorPctList, totalScores) = h2o_rf.simpleCheckRFView(rfv=rfv, ntree=used_trees)
        oobeTrainPctRight = (100.0 - classification_error)
        expectTrainPctRight = 94
        h2o_util.assertApproxEqual(oobeTrainPctRight, expectTrainPctRight, rel=0.1, msg=('OOBE: pct. right for training not close enough %6.2f %6.2f' % (oobeTrainPctRight, expectTrainPctRight)))
        print 'Now score with the 2nd random dataset'
        rfv = h2o_cmd.runRFView(data_key=dataKeyTest, model_key=model_key, timeoutSecs=timeoutSecs, retryDelaySecs=1)
        (classification_error, classErrorPctList, totalScores) = h2o_rf.simpleCheckRFView(rfv=rfv, ntree=used_trees)
        h2o_util.assertApproxEqual(classification_error, 8.0, tol=4, msg=('Classification error %s too big' % classification_error))
        predict = h2o.nodes[0].generate_predictions(model_key=model_key, data_key=dataKeyTest)
        fullScorePctRight = (100.0 - classification_error)
        expectScorePctRight = 94
        h2o_util.assertApproxEqual(fullScorePctRight, expectScorePctRight, rel=0.1, msg=('Full: pct. right for scoring not close enough %6.2f %6.2f' % (fullScorePctRight, expectScorePctRight)))
