{
  epoch_counter=(float)model_info().get_processed_total() / model_info().data_info._adaptedFrame.numRows();
  run_time=(System.currentTimeMillis() - start_time);
  boolean keep_running=(epoch_counter < model_info().parameters.epochs);
  _now=System.currentTimeMillis();
  final long sinceLastScore=_now - _timeLastScoreStart;
  final long sinceLastPrint=_now - _timeLastPrintStart;
  final long samples=model_info().get_processed_total();
  if (sinceLastPrint > model_info().parameters.score_interval * 1000) {
    _timeLastPrintStart=_now;
    Log.info("Training time: " + PrettyPrint.msecs(_now - start_time,true) + " processed "+ samples+ " samples"+ " ("+ String.format("%.3f",epoch_counter)+ " epochs)."+ " Speed: "+ String.format("%.3f",(double)samples / ((_now - start_time) / 1000.))+ " samples/sec.");
  }
  if (!keep_running || sinceLastScore > model_info().parameters.score_interval * 1000) {
    final boolean printme=!model_info().get_params().quiet_mode;
    if (printme)     Log.info("Scoring the model.");
    _timeLastScoreStart=_now;
    Errors err=new Errors();
    err.classification=isClassifier();
    assert(err.classification == model_info().get_params().classification);
    err.training_time_ms=_now - timeStart;
    err.epoch_counter=epoch_counter;
    err.validation=ftest != null;
    err.training_samples=model_info().get_processed_total();
    err.score_training_samples=ftrain.numRows();
    err.train_confusion_matrix=new ConfusionMatrix();
    final double trainErr=calcError(ftrain,"Scoring on training data:",printme,err.train_confusion_matrix);
    if (err.classification)     err.train_err=trainErr;
 else     err.train_mse=trainErr;
    if (err.validation) {
      err.score_validation_samples=ftest.numRows();
      err.valid_confusion_matrix=new ConfusionMatrix();
      final double validErr=calcError(ftest,"Scoring on validation data:",printme,err.valid_confusion_matrix);
      if (err.classification)       err.valid_err=validErr;
 else       err.valid_mse=validErr;
    }
    if (errors == null) {
      errors=new Errors[]{err};
    }
 else {
      Errors[] err2=new Errors[errors.length + 1];
      System.arraycopy(errors,0,err2,0,errors.length);
      err2[err2.length - 1]=err;
      errors=err2;
    }
    for (    String s : toString().split("\n"))     Log.info(s);
    if (printme)     Log.info("Scoring time: " + PrettyPrint.msecs(System.currentTimeMillis() - _now,true));
  }
  if (model_info().unstable()) {
    Log.err("Canceling job since the model is unstable (exponential growth observed).");
    Log.err("Try a bounded activation function or regularization with L1, L2 or max_w2 and/or use a smaller learning rate or faster annealing.");
    keep_running=false;
  }
 else   if (ftest == null && (model_info().get_params().classification && errors[errors.length - 1].train_err <= model_info().get_params().classification_stop) || (!model_info().get_params().classification && errors[errors.length - 1].train_mse <= model_info().get_params().regression_stop)) {
    Log.info("Achieved requested predictive accuracy on the training data. Model building completed.");
    keep_running=false;
  }
 else   if (ftest != null && (model_info().get_params().classification && errors[errors.length - 1].valid_err <= model_info().get_params().classification_stop) || (!model_info().get_params().classification && errors[errors.length - 1].valid_mse <= model_info().get_params().regression_stop)) {
    Log.info("Achieved requested predictive accuracy on the validation data. Model building completed.");
    keep_running=false;
  }
  update(job_key);
  return keep_running;
}
