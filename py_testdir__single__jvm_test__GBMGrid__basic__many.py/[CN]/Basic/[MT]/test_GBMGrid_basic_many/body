def test_GBMGrid_basic_many(self):
    csvFilename = 'prostate.csv'
    print '\nStarting', csvFilename
    csvPathname = ('logreg/' + csvFilename)
    parseResult = h2i.import_parse(bucket='smalldata', path=csvPathname, hex_key=(csvFilename + '.hex'), schema='put')
    colNames = ['ID', 'CAPSULE', 'AGE', 'RACE', 'DPROS', 'DCAPS', 'PSA', 'VOL', 'GLEASON']
    modelKey = 'GBMGrid_prostate'
    params = {'destination_key': modelKey, 'ignored_cols_by_name': 'ID', 'learn_rate': '.1,.2', 'ntrees': '5,8', 'max_depth': '8,9', 'min_rows': '1,5', 'response': 'CAPSULE', 'classification': (1 if DO_CLASSIFICATION else 0), }
    kwargs = params.copy()
    timeoutSecs = 1800
    jobs = []
    start = time.time()
    totalGBMGridJobs = 0
    for more in range(10):
        for i in range(5, 10):
            kwargs = params.copy()
            kwargs['min_rows'] = ('1,' + str(i))
            kwargs['max_depth'] = ('5,' + str(i))
            GBMResult = h2o_cmd.runGBM(parseResult=parseResult, noPoll=True, **kwargs)
            job_key = GBMResult['job_key']
            model_key = GBMResult['destination_key']
            jobs.append((job_key, model_key))
            totalGBMGridJobs += 1
    h2o_jobs.pollWaitJobs(timeoutSecs=300)
    elapsed = (time.time() - start)
    print 'All GBM jobs completed in', elapsed, 'seconds.'
    for (job_key, model_key) in jobs:
        GBMResult = h2o.nodes[0].gbm_grid_view(job_key=job_key, destination_key=model_key)
        showResults(GBMResult, 15)
    print 'totalGBMGridJobs:', totalGBMGridJobs
