def import_only(node=None, schema='local', bucket=None, path=None, timeoutSecs=30, retryDelaySecs=0.5, initialDelaySecs=0.5, pollTimeoutSecs=180, noise=None, benchmarkLogging=None, noPoll=False, doSummary=True, src_key='python_src_key', **kwargs):
    if (not node):
        node = h2o.nodes[0]
    if (path is None):
        raise Exception('import_only: path parameter needs to be specified')
    if ('/' in path):
        (head, pattern) = os.path.split(path)
    else:
        (head, pattern) = ('', path)
    h2o.verboseprint('head:', head)
    h2o.verboseprint('pattern:', pattern)
    if re.search('[\\*<>{}[\\]~`]', head):
        raise Exception(("h2o folder path %s can't be regex. path= was %s" % (head, path)))
    if (schema == 'put'):
        if re.search('[/\\*<>{}[\\]~`]', pattern):
            raise Exception(("h2o putfile basename %s can't be regex. path= was %s" % (pattern, path)))
        if (not path):
            raise Exception("path= didn't say what file to put")
        (folderPath, filename) = find_folder_and_filename(bucket, path, schema)
        h2o.verboseprint('folderPath:', folderPath, 'filename:', filename)
        filePath = os.path.join(folderPath, filename)
        h2o.verboseprint('filePath:', filePath)
        key = node.put_file(filePath, key=src_key, timeoutSecs=timeoutSecs)
        return (None, key)
    if ((schema == 'local') and (not (node.redirect_import_folder_to_s3_path or node.redirect_import_folder_to_s3n_path))):
        (folderPath, pattern) = find_folder_and_filename(bucket, path, schema)
        folderURI = ('nfs:/' + folderPath)
        importResult = node.import_files(folderPath, timeoutSecs=timeoutSecs)
    else:
        if ((bucket is not None) and re.match('/', head)):
            h2o.verboseprint('You said bucket:', bucket, "so stripping incorrect leading '/' from", head)
            head = head.lstrip('/')
        if (bucket and (head != '')):
            folderOffset = ((bucket + '/') + head)
        elif bucket:
            folderOffset = bucket
        else:
            folderOffset = head
        if ((schema == 's3') or node.redirect_import_folder_to_s3_path):
            folderURI = ('s3://' + folderOffset)
            importResult = node.import_s3(bucket, timeoutSecs=timeoutSecs)
        elif ((schema == 's3n') or node.redirect_import_folder_to_s3n_path):
            folderURI = ('s3n://' + folderOffset)
            importResult = node.import_hdfs(folderURI, timeoutSecs=timeoutSecs)
        elif (schema == 'maprfs'):
            folderURI = ('hdfs:///' + folderOffset)
            importResult = node.import_hdfs(folderURI, timeoutSecs=timeoutSecs)
        elif (schema == 'hdfs'):
            h2o.verboseprint(h2o.nodes[0].hdfs_name_node)
            h2o.verboseprint('folderOffset;', folderOffset)
            folderURI = ((('hdfs://' + h2o.nodes[0].hdfs_name_node) + '/') + folderOffset)
            importResult = node.import_hdfs(folderURI, timeoutSecs=timeoutSecs)
        else:
            raise Exception(('schema not understood: %s' % schema))
    importPattern = ((folderURI + '/') + pattern)
    return (importResult, importPattern)
