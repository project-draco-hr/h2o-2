{
  System.err.printf("\n" + "Usage: h2odriver\n" + "          -files <.../flatfile.txt>\n"+ "          -libjars <.../h2o.jar>\n"+ "          [other generic Hadoop ToolRunner options]\n"+ "          [-h | -help]\n"+ "          [-jobname <name of job in jobtracker (defaults to: 'H2O_nnnnn')>]\n"+ "              (Note nnnnn is chosen randomly to produce a unique name)\n"+ "          [-driverif <ip address of mapper->driver callback interface>]\n"+ "          [-driverport <port of mapper->driver callback interface>]\n"+ "          [-disown]\n"+ "          [-notify <notification file name>]\n"+ "          -mapperXmx <per mapper Java Xmx heap size>\n"+ "          -n | -nodes <number of H2O nodes (i.e. mappers) to create>\n"+ "          -o | -output <hdfs output dir>\n"+ "\n"+ "Notes:\n"+ "          o  Each H2O node runs as a mapper.\n"+ "          o  Only one mapper may be run per host.\n"+ "          o  There are no combiners or reducers.\n"+ "          o  Each H2O cluster should have a unique jobname.\n"+ "          o  -mapperXmx, -nodes and -output are required.\n"+ "\n"+ "          o  -mapperXmx is set to both Xms and Xmx of the mapper to reserve\n"+ "             memory up front.\n"+ "          o  -files flatfile.txt is required and must be named flatfile.txt.\n"+ "          o  -libjars with an h2o.jar is required.\n"+ "          o  -driverif and -driverport let the user optionally specify the\n"+ "             network interface and port (on the driver host) for callback\n"+ "             messages from the mapper to the driver.\n"+ "          o  -disown causes the driver to exit as soon as the cloud forms.\n"+ "             Otherwise, Ctrl-C of the driver kills the Hadoop Job.\n"+ "          o  -notify specifies a file to write when the cluster is up.\n"+ "             The file contains one line with the IP and port of the embedded\n"+ "             web server for one of the H2O nodes in the cluster.  e.g.\n"+ "                 192.168.1.100:54321\n"+ "          o  All mappers must start before the H2O cloud is considered up.\n"+ "\n"+ "Examples:\n"+ "          hadoop jar h2odriver_HHH.jar water.hadoop.h2odriver -jt <yourjobtracker>:<yourport> -files flatfile.txt -libjars h2o.jar -mapperXmx 1g -nodes 1 -output hdfsOutputDir\n"+ "          hadoop jar h2odriver_HHH.jar water.hadoop.h2odriver -jt <yourjobtracker>:<yourport> -files flatfile.txt -libjars h2o.jar -mapperXmx 1g -nodes 1 -notify notify.txt -disown -output hdfsOutputDir\n"+ "          (Choose the proper h2odriver (_HHH) for your version of hadoop.\n"+ "\n"+ "flatfile.txt:\n"+ "          The flat file must contain the list of possible IP addresses an H2O\n"+ "          node (i.e. mapper) may be scheduled on.  One IP address per line.\n"+ "          For example:\n"+ "              192.168.1.100\n"+ "              192.168.1.101\n"+ "              etc.\n"+ "\n"+ "Exit value:\n"+ "          0 means the cluster exited successfully with an orderly Shutdown.\n"+ "              (From the Web UI or the REST API.)\n"+ "\n"+ "          non-zero means the cluster exited with a failure.\n"+ "              (Note that Ctrl-C is treated as a failure.)\n"+ "\n");
  System.exit(1);
}
