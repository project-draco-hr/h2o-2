def test_RF_mnist_reals(self):
    importFolderPath = 'mnist'
    csvFilelist = [('mnist_reals_training.csv.gz', 'mnist_reals_testing.csv.gz', 600)]
    trial = 0
    for (trainCsvFilename, testCsvFilename, timeoutSecs) in csvFilelist:
        trialStart = time.time()
        testKey2 = (((testCsvFilename + '_') + str(trial)) + '.hex')
        start = time.time()
        parseResult = h2i.import_parse(bucket='home-0xdiag-datasets', path=((importFolderPath + '/') + testCsvFilename), hex_key=testKey2, timeoutSecs=timeoutSecs)
        elapsed = (time.time() - start)
        print 'parse end on ', testCsvFilename, 'took', elapsed, 'seconds', ('%d pct. of timeout' % ((elapsed * 100) / timeoutSecs))
        print 'parse result:', parseResult['destination_key']
        print "We won't use this pruning of x on test data. See if it prunes the same as the training"
        y = 0
        print 'y:'
        x = h2o_glm.goodXFromColumnInfo(y, key=parseResult['destination_key'], timeoutSecs=300)
        trainKey2 = (((trainCsvFilename + '_') + str(trial)) + '.hex')
        start = time.time()
        parseResult = h2i.import_parse(bucket='home-0xdiag-datasets', path=((importFolderPath + '/') + trainCsvFilename), hex_key=trainKey2, timeoutSecs=timeoutSecs)
        elapsed = (time.time() - start)
        print 'parse end on ', trainCsvFilename, 'took', elapsed, 'seconds', ('%d pct. of timeout' % ((elapsed * 100) / timeoutSecs))
        print 'parse result:', parseResult['destination_key']
        print "This is the 'ignore=' we'll use"
        ignore_x = h2o_glm.goodXFromColumnInfo(y, key=parseResult['destination_key'], timeoutSecs=300, forRF=True)
        ntree = 10
        params = {'response_variable': 0, 'ignore': ignore_x, 'ntree': ntree, 'iterative_cm': 1, 'out_of_bag_error_estimate': 1, 'features': 28, 'exclusive_split_limit': None, 'depth': 2147483647, 'stat_type': 'ENTROPY', 'sampling_strategy': 'RANDOM', 'sample': 67, 'model_key': 'RF_model', 'bin_limit': 1024, 'seed': 784834182943470027, 'parallel': 1, 'use_non_local_data': 0, 'class_weights': '0=1.0,1=1.0,2=1.0,3=1.0,4=1.0,5=1.0,6=1.0,7=1.0,8=1.0,9=1.0', }
        kwargs = params.copy()
        print 'Trying rf'
        timeoutSecs = 1800
        start = time.time()
        rfView = h2o_cmd.runRF(parseResult=parseResult, rfView=True, timeoutSecs=timeoutSecs, pollTimeoutsecs=60, retryDelaySecs=2, **kwargs)
        elapsed = (time.time() - start)
        print 'RF completed in', elapsed, 'seconds.', ('%d pct. of timeout' % ((elapsed * 100) / timeoutSecs))
        h2o_rf.simpleCheckRFView(None, rfView, **params)
        modelKey = rfView['model_key']
        start = time.time()
        kwargs = {'response_variable': y, }
        rfView = h2o_cmd.runRFView(data_key=testKey2, model_key=modelKey, ntree=ntree, out_of_bag_error_estimate=0, timeoutSecs=60, pollTimeoutSecs=60, noSimpleCheck=False, **kwargs)
        elapsed = (time.time() - start)
        print 'RFView in', elapsed, 'secs', ('%d pct. of timeout' % ((elapsed * 100) / timeoutSecs))
        (classification_error, classErrorPctList, totalScores) = h2o_rf.simpleCheckRFView(None, rfView, **params)
        self.assertAlmostEqual(classification_error, 0.03, delta=0.5, msg=('Classification error %s differs too much' % classification_error))
        start = time.time()
        predict = h2o.nodes[0].generate_predictions(model_key=modelKey, data_key=testKey2, timeoutSecs=timeoutSecs)
        elapsed = (time.time() - start)
        print 'generate_predictions in', elapsed, 'secs', ('%d pct. of timeout' % ((elapsed * 100) / timeoutSecs))
