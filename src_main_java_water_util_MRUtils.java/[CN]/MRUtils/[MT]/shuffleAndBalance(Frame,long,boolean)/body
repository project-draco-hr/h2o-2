{
  int cores=0;
  for (  H2ONode node : H2O.CLOUD._memary)   cores+=node._heartbeat._num_cpus;
  final int splits=4 * cores;
  Vec[] vecs=fr.vecs();
  if (vecs[0].nChunks() < splits / 4 || shuffle) {
    Log.info("Load balancing dataset, splitting it into up to " + splits + " chunks.");
    long[] idx=null;
    if (shuffle) {
      idx=new long[splits];
      for (int r=0; r < idx.length; ++r)       idx[r]=r;
      Utils.shuffleArray(idx,seed);
    }
    Key keys[]=new Vec.VectorGroup().addVecs(vecs.length);
    final long rows_per_new_chunk=(long)(Math.ceil((double)fr.numRows() / splits));
    Futures fs=new Futures();
    for (int col=0; col < vecs.length; col++) {
      AppendableVec vec=new AppendableVec(keys[col]);
      NewChunk[] outCkg=new NewChunk[splits];
      for (int i=0; i < splits; ++i)       outCkg[i]=new NewChunk(vec,i);
      for (int ckg=0; ckg < vecs[col].nChunks(); ckg++) {
        final Chunk inCkg=vecs[col].chunkForChunkIdx(ckg);
        for (int row=0; row < inCkg._len; ++row) {
          int outCkgIdx=(int)((inCkg._start + row) / rows_per_new_chunk);
          if (shuffle)           outCkgIdx=(int)(idx[outCkgIdx]);
          assert(outCkgIdx >= 0 && outCkgIdx < splits);
          outCkg[outCkgIdx].addNum(inCkg.at0(row));
        }
      }
      for (int i=0; i < outCkg.length; ++i)       outCkg[i].close(i,fs);
      Vec t=vec.close(fs);
      t._domain=vecs[col]._domain;
      vecs[col]=t;
    }
    fs.blockForPending();
    Log.info("Load balancing done.");
  }
  fr.reloadVecs();
  return new Frame(fr.names(),vecs);
}
