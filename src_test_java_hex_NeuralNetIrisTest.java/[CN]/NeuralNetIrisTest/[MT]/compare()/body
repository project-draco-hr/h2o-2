{
  float rate=0.01f;
  float momentum=0;
  int epochs=1000;
  Layer[] ls=new Layer[3];
  ls[0]=_train;
  ls[1]=new Layer.Tanh();
  ls[1]._rate=rate;
  ls[1].init(ls[0],7);
  ls[2]=new Softmax();
  ls[2]._rate=rate;
  ls[2].init(ls[1],3);
  for (int i=1; i < ls.length; i++)   ls[i].randomize();
  NeuralNetMLPReference ref=new NeuralNetMLPReference();
  ref.init();
  Layer l=ls[1];
  for (int o=0; o < l._a.length; o++) {
    for (int i=0; i < l._in._a.length; i++)     ref._nn.ihWeights[i][o]=l._w[o * l._in._a.length + i];
    ref._nn.hBiases[o]=l._b[o];
  }
  l=ls[2];
  for (int o=0; o < l._a.length; o++) {
    for (int i=0; i < l._in._a.length; i++)     ref._nn.hoWeights[i][o]=l._w[o * l._in._a.length + i];
    ref._nn.oBiases[o]=l._b[o];
  }
  ref.train(epochs,rate,momentum);
  Trainer.Direct trainer=new Trainer.Direct(ls);
  trainer._batches=epochs * (int)_train._frame.numRows();
  trainer._batch=1;
  trainer.run();
  float epsilon=1e-4f;
  for (int o=0; o < ls[2]._a.length; o++) {
    float a=ref._nn.outputs[o];
    float b=ls[2]._a[o];
    Assert.assertEquals(a,b,epsilon);
  }
  l=ls[1];
  for (int o=0; o < l._a.length; o++) {
    for (int i=0; i < l._in._a.length; i++) {
      float a=ref._nn.ihWeights[i][o];
      float b=l._w[o * l._in._a.length + i];
      Assert.assertEquals(a,b,epsilon);
    }
  }
  NeuralNet.Error train=NeuralNetScore.eval(ls,NeuralNet.EVAL_ROW_COUNT);
  ls[0]=_test;
  ls[1]._in=_test;
  NeuralNet.Error test=NeuralNetScore.eval(ls,NeuralNet.EVAL_ROW_COUNT);
  float trainAcc=ref._nn.Accuracy(ref._trainData);
  Assert.assertEquals(trainAcc,train.Value,epsilon);
  float testAcc=ref._nn.Accuracy(ref._testData);
  Assert.assertEquals(testAcc,test.Value,epsilon);
  Log.info("H2O and Reference equal, train: " + train + ", test: "+ test);
}
