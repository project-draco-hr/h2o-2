def sub_c3_nongz_fvec_long(self, csvFilenameList):
    h2o.setup_benchmark_log()
    bucket = 'home-0xdiag-datasets'
    importFolderPath = 'manyfiles-nflx'
    print "Using nongz'ed files in", importFolderPath
    if LOG_MACHINE_STATS:
        benchmarkLogging = ['cpu', 'disk', 'network']
    else:
        benchmarkLogging = []
    pollTimeoutSecs = 120
    retryDelaySecs = 10
    for (trial, (csvFilepattern, csvFilename, totalBytes, timeoutSecs)) in enumerate(csvFilenameList):
        csvPathname = ((importFolderPath + '/') + csvFilepattern)
        if DO_DOUBLE_IMPORT:
            (importResult, importPattern) = h2i.import_only(bucket=bucket, path=csvPathname, schema='local')
            importFullList = importResult['files']
            importFailList = importResult['fails']
            print '\n Problem if this is not empty: importFailList:', h2o.dump_json(importFailList)
        h2o.cloudPerfH2O.change_logfile(csvFilename)
        h2o.cloudPerfH2O.message('')
        h2o.cloudPerfH2O.message((('Parse ' + csvFilename) + ' Start--------------------------------'))
        start = time.time()
        parseResult = h2i.import_parse(bucket=bucket, path=csvPathname, schema='local', hex_key='A.hex', timeoutSecs=timeoutSecs, retryDelaySecs=retryDelaySecs, pollTimeoutSecs=pollTimeoutSecs, benchmarkLogging=benchmarkLogging)
        elapsed = (time.time() - start)
        print 'Parse #', trial, 'completed in', ('%6.2f' % elapsed), 'seconds.', ('%d pct. of timeout' % ((elapsed * 100) / timeoutSecs))
        print "Parse result['destination_key']:", parseResult['destination_key']
        h2o_cmd.columnInfoFromInspect(parseResult['destination_key'], exceptionOnMissingValues=False)
        if (totalBytes is not None):
            fileMBS = ((totalBytes / 1000000.0) / elapsed)
            msg = '{!s} jvms, {!s}GB heap, {:s} {:s} {:6.2f} MB/sec for {:.2f} secs'.format(len(h2o.nodes), h2o.nodes[0].java_heap_GB, csvFilepattern, csvFilename, fileMBS, elapsed)
            print msg
            h2o.cloudPerfH2O.message(msg)
        if DO_GLM:
            ignore_x = [3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 16, 17, 18, 19, 20, 424, 425, 426, 540, 541]
            ignore_x = ','.join(map((lambda x: ('C' + str((x + 1)))), ignore_x))
            GLMkwargs = {'ignored_cols': ignore_x, 'response': 'C379', 'max_iter': 10, 'n_folds': 1, 'family': 'binomial', 'alpha': 0.2, 'lambda': 1e-05, }
            h2i.delete_keys_at_all_nodes(pattern='manyfile')
            execExpr = 'A.hex[,378+1]=(A.hex[,378+1]>15)'
            h2e.exec_expr(execExpr=execExpr, timeoutSecs=180)
            aHack = {'destination_key': 'A.hex', }
            start = time.time()
            glm = h2o_cmd.runGLM(parseResult=aHack, timeoutSecs=timeoutSecs, **GLMkwargs)
            elapsed = (time.time() - start)
            h2o.check_sandbox_for_errors()
            h2o_glm.simpleCheckGLM(self, glm, None, **GLMkwargs)
            msg = '{:d} jvms, {:d}GB heap, {:s} {:s} GLM: {:6.2f} secs'.format(len(h2o.nodes), h2o.nodes[0].java_heap_GB, csvFilepattern, csvFilename, elapsed)
            print msg
            h2o.cloudPerfH2O.message(msg)
        h2o_cmd.checkKeyDistribution()
