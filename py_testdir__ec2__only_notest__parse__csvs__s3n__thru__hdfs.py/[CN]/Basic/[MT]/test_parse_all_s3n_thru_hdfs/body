def test_parse_all_s3n_thru_hdfs(self):
    print '\nLoad a list of files from s3n, parse it thru HDFS'
    print "In EC2, michal's config always passes the right config xml"
    print 'as arg to the java -jar h2o.jar. Only works in EC2'
    bucket = 'home-0xdiag-datasets'
    csvPathname = 'standard/*'
    importResult = h2i.import_only(bucket=bucket, path=csvPathname, schema='s3n')
    s3nFullList = importResult['succeeded']
    print 's3nFullList:', h2o.dump_json(s3nFullList)
    self.assertGreater(len(s3nFullList), 1, "Didn't see more than 1 files in s3n?")
    s3nList = random.sample(s3nFullList, 8)
    timeoutSecs = 500
    for s in s3nList:
        s3nKey = s['key']
        s3nFilename = s['file']
        if (('csv' not in s3nKey) or ('syn_dataset' in s3nKey) or ('.gz' in s3nKey)):
            continue
        print 'Loading s3n key: ', s3nKey, 'thru HDFS'
        parseResult = h2i.parse_only(pattern=s3nKey, hex_key=(s3nFilename + '.hex'), timeoutSecs=timeoutSecs, retryDelaySecs=10, pollTimeoutSecs=60)
        print 'parse result:', parseResult['destination_key']
        start = time.time()
        sys.stdout.flush()
