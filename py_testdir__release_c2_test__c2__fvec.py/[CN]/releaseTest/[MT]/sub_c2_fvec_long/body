def sub_c2_fvec_long(self):
    h2o.setup_benchmark_log()
    avgMichalSize = 116561140
    bucket = 'home-0xdiag-datasets'
    importFolderPath = 'manyfiles-nflx-gz'
    print "Using .gz'ed files in", importFolderPath
    csvFilenameList = [('*[1][0-4][0-9].dat.gz', 'file_50_A.dat.gz', (50 * avgMichalSize), 900)]
    if LOG_MACHINE_STATS:
        benchmarkLogging = ['cpu', 'disk', 'network']
    else:
        benchmarkLogging = []
    pollTimeoutSecs = 120
    retryDelaySecs = 10
    for (trial, (csvFilepattern, csvFilename, totalBytes, timeoutSecs)) in enumerate(csvFilenameList):
        csvPathname = ((importFolderPath + '/') + csvFilepattern)
        h2o.cloudPerfH2O.change_logfile(csvFilename)
        h2o.cloudPerfH2O.message('')
        h2o.cloudPerfH2O.message((('Parse ' + csvFilename) + ' Start--------------------------------'))
        start = time.time()
        parseResult = h2i.import_parse(bucket=bucket, path=csvPathname, schema='local', hex_key=(csvFilename + '.hex'), timeoutSecs=timeoutSecs, doSummary=False, retryDelaySecs=retryDelaySecs, pollTimeoutSecs=pollTimeoutSecs, benchmarkLogging=benchmarkLogging)
        elapsed = (time.time() - start)
        print 'Parse #', trial, 'completed in', ('%6.2f' % elapsed), 'seconds.', ('%d pct. of timeout' % ((elapsed * 100) / timeoutSecs))
        print "Parse result['destination_key']:", parseResult['destination_key']
        h2o_cmd.columnInfoFromInspect(parseResult['destination_key'], exceptionOnMissingValues=False)
        inspect = h2o_cmd.runInspect(key=parseResult['destination_key'])
        h2o_cmd.infoFromInspect(inspect, csvPathname)
        numRows = inspect['numRows']
        numCols = inspect['numCols']
        summaryResult = h2o_cmd.runSummary(key=parseResult['destination_key'], timeoutSecs=timeoutSecs, numCols=numCols, numRows=numRows)
        if (totalBytes is not None):
            fileMBS = ((totalBytes / 1000000.0) / elapsed)
            msg = '{!s} jvms, {!s}GB heap, {:s} {:s} {:6.2f} MB/sec for {:.2f} secs'.format(len(h2o.nodes), h2o.nodes[0].java_heap_GB, csvFilepattern, csvFilename, fileMBS, elapsed)
            print msg
            h2o.cloudPerfH2O.message(msg)
        if DO_GLM:
            ignore_x = [3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 16, 17, 18, 19, 20, 424, 425, 426, 540, 541]
            ignore_x = ','.join(map((lambda x: ('C' + str((x + 1)))), ignore_x))
            GLMkwargs = {'ignored_cols': ignore_x, 'family': 'binomial', 'response': 'C379', 'max_iter': 10, 'n_folds': 1, 'family': 'binomial', 'alpha': 0.2, 'lambda': 1e-05, }
            execExpr = ('A.hex=%s' % parseResult['destination_key'])
            h2e.exec_expr(execExpr=execExpr, timeoutSecs=180)
            execExpr = ('A.hex[,%s]=(A.hex[,%s]>%s)' % ('379', '379', 15))
            h2e.exec_expr(execExpr=execExpr, timeoutSecs=180)
            aHack = {'destination_key': 'A.hex', }
            start = time.time()
            glm = h2o_cmd.runGLM(parseResult=aHack, timeoutSecs=timeoutSecs, **GLMkwargs)
            elapsed = (time.time() - start)
            h2o.check_sandbox_for_errors()
            h2o_glm.simpleCheckGLM(self, glm, None, **GLMkwargs)
            msg = '{:d} jvms, {:d}GB heap, {:s} {:s} GLM: {:6.2f} secs'.format(len(h2o.nodes), h2o.nodes[0].java_heap_GB, csvFilepattern, csvFilename, elapsed)
            print msg
            h2o.cloudPerfH2O.message(msg)
        h2o_cmd.checkKeyDistribution()
