{
  long seed=0xDECAF;
  Key file_train=NFSFileVec.make(find_test_file(PATH));
  Frame train=ParseDataset2.parse(Key.make(),new Key[]{file_train});
  DeepLearning p=new DeepLearning();
  p.source=train;
  p.autoencoder=true;
  p.response=train.vecs()[0];
  p.classification=true;
  p.seed=seed;
  p.hidden=new int[]{20};
  p.adaptive_rate=true;
  p.l1=1e-4;
  p.activation=DeepLearning.Activation.Tanh;
  p.loss=DeepLearning.Loss.MeanSquare;
  p.epochs=10;
  p.force_load_balance=false;
  p.invoke();
  DeepLearningModel mymodel=UKV.get(p.dest());
  StringBuilder sb=new StringBuilder();
  sb.append("Verifying results.");
  double quantile=0.95;
  final Frame l2_frame_train=mymodel.scoreAutoEncoder(train);
  final Vec l2_train=l2_frame_train.anyVec();
  double thresh_train=mymodel.calcOutlierThreshold(l2_train,quantile);
  sb.append("Mean reconstruction error: " + l2_train.mean() + "\n");
  Assert.assertEquals(mymodel.mse(),l2_train.mean(),1e-6);
  Frame reconstr=mymodel.score(train);
  double mean_l2=0;
  for (int r=0; r < reconstr.numRows(); ++r) {
    double my_l2=0;
    for (int c=0; c < reconstr.numCols(); ++c) {
      my_l2+=Math.pow((reconstr.vec(c).at(r) - train.vec(c).at(r)) * mymodel.model_info().data_info()._normMul[c],2);
    }
    mean_l2+=my_l2;
  }
  mean_l2/=reconstr.numRows();
  reconstr.delete();
  sb.append("Mean reconstruction error (train): " + l2_train.mean() + "\n");
  Assert.assertEquals(mymodel.mse(),mean_l2,1e-6);
  sb.append("The following training points are reconstructed with an error above the " + quantile * 100 + "-th percentile - check for \"goodness\" of training data.\n");
  for (long i=0; i < l2_train.length(); i++) {
    if (l2_train.at(i) > thresh_train) {
      sb.append(String.format("row %d : l2_train error = %5f\n",i,l2_train.at(i)));
    }
  }
  p.delete();
  mymodel.delete();
  train.delete();
  l2_frame_train.delete();
}
