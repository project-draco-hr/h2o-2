def test_benchmark_import(self):
    if (1 == 0):
        importFolderPath = '/home2/0xdiag/datasets'
        print "Using non-.gz'ed files in", importFolderPath
        avgMichalSize = 116561140
        csvFilenameAll = [('manyfiles-nflx/file_1.dat', 'file_1.dat', (1 * avgMichalSize), 700), ('manyfiles-nflx/file_[2][0-9].dat', 'file_10.dat', (10 * avgMichalSize), 700), ('manyfiles-nflx/file_[34][0-9].dat', 'file_20.dat', (20 * avgMichalSize), 700), ('manyfiles-nflx/file_[5-9][0-9].dat', 'file_50.dat', (50 * avgMichalSize), 700)]
    elif (1 == 0):
        importFolderPath = '/home2/0xdiag/datasets'
        print "Using non-.gz'ed files in", importFolderPath
        avgMichalSize = 116561140
        csvFilenameAll = [('onefile-nflx/file_1_to_100.dat', 'file_single.dat', (100 * avgMichalSize), 1200), ('manyfiles-nflx/file_[0-9][0-9]*.dat', 'file_100.dat', (100 * avgMichalSize), 1200), ('manyfiles-nflx/file_1.dat', 'file_1.dat', (1 * avgMichalSize), 700), ('manyfiles-nflx/file_[2][0-9].dat', 'file_10.dat', (10 * avgMichalSize), 700), ('manyfiles-nflx/file_[34][0-9].dat', 'file_20.dat', (20 * avgMichalSize), 700), ('manyfiles-nflx/file_[5-9][0-9].dat', 'file_50.dat', (50 * avgMichalSize), 700)]
    else:
        importFolderPath = '/home/0xdiag/datasets'
        print "Using .gz'ed files in", importFolderPath
        avgMichalSize = 237270000
        avgSynSize = 4020000
        csvFilenameAll = [('covtype200x.data', 'covtype200x.data', 15033863400, 700), ('syn_datasets/syn_7350063254201195578_10000x200.csv_000[0-9][0-9]', 'syn_100.csv', (100 * avgSynSize), 700), ('manyfiles-nflx-gz/file_1.dat.gz', 'file_1.dat.gz', (1 * avgMichalSize), 700), ('syn_datasets/syn_7350063254201195578_10000x200.csv_00000', 'syn_1.csv', avgSynSize, 700), ('syn_datasets/syn_7350063254201195578_10000x200.csv_0001[0-9]', 'syn_10.csv', (10 * avgSynSize), 700), ('syn_datasets/syn_7350063254201195578_10000x200.csv_000[23][0-9]', 'syn_20.csv', (20 * avgSynSize), 700), ('syn_datasets/syn_7350063254201195578_10000x200.csv_000[45678][0-9]', 'syn_50.csv', (50 * avgSynSize), 700), ('manyfiles-nflx-gz/file_[2][0-9].dat.gz', 'file_10.dat.gz', (10 * avgMichalSize), 700), ('manyfiles-nflx-gz/file_[34][0-9].dat.gz', 'file_20.dat.gz', (20 * avgMichalSize), 700), ('manyfiles-nflx-gz/file_[5-9][0-9].dat.gz', 'file_50.dat.gz', (50 * avgMichalSize), 700)]
    csvFilenameList = csvFilenameAll
    trialMax = 1
    base_port = 54321
    tryHeap = 28
    noPoll = False
    benchmarkLogging = ['cpu', 'disk']
    for (csvFilepattern, csvFilename, totalBytes, timeoutSecs) in csvFilenameList:
        localhost = h2o.decide_if_localhost()
        if localhost:
            h2o.build_cloud(1, java_heap_GB=tryHeap, base_port=base_port, enable_benchmark_log=True)
        else:
            h2o_hosts.build_cloud_with_hosts(1, java_heap_GB=tryHeap, base_port=base_port, enable_benchmark_log=True)
        for trial in range(trialMax):
            importFolderResult = h2i.setupImportFolder(None, importFolderPath)
            importFullList = importFolderResult['succeeded']
            importFailList = importFolderResult['failed']
            print '\n Problem if this is not empty: importFailList:', h2o.dump_json(importFailList)
            h2o.cloudPerfH2O.change_logfile(csvFilename)
            h2o.cloudPerfH2O.message('')
            h2o.cloudPerfH2O.message((('Parse ' + csvFilename) + ' Start--------------------------------'))
            start = time.time()
            parseKey = h2i.parseImportFolderFile(None, csvFilepattern, importFolderPath, key2=(csvFilename + '.hex'), timeoutSecs=timeoutSecs, retryDelaySecs=5, noPoll=noPoll, benchmarkLogging=benchmarkLogging)
            elapsed = (time.time() - start)
            print 'Parse #', trial, 'completed in', ('%6.2f' % elapsed), 'seconds.', ('%d pct. of timeout' % ((elapsed * 100) / timeoutSecs))
            if (totalBytes is not None):
                fileMBS = ((totalBytes / 1000000.0) / elapsed)
                print '\nMB/sec (before uncompress)', ('%6.2f' % fileMBS)
                h2o.cloudPerfH2O.message('{!s} jvms, {!s}GB heap, {:s} {:s} {:6.2f} MB/sec for {:.2f} secs'.format(len(h2o.nodes), tryHeap, csvFilepattern, csvFilename, fileMBS, elapsed))
            print csvFilepattern, 'parse time:', parseKey['response']['time']
            print "Parse result['destination_key']:", parseKey['destination_key']
            time.sleep(2)
            h2o_jobs.pollWaitJobs(pattern=csvFilename, benchmarkLogging=benchmarkLogging)
            inspect = h2o_cmd.runInspect(key=parseKey['destination_key'])
            print 'num_rows:', inspect['num_rows']
            print 'num_cols:', inspect['num_cols']
            cols = inspect['cols']
            for (i, c) in enumerate(cols):
                msg = ('column %d' % i)
                msg = (msg + (' type: %s' % c['type']))
                if (c['type'] == 'enum'):
                    msg = (msg + (' enum_domain_size: %d' % c['enum_domain_size']))
                if (c['num_missing_values'] != 0):
                    msg = (msg + (' num_missing_values: %s' % c['num_missing_values']))
                if ((c['type'] != 'int') or (c['num_missing_values'] != 0)):
                    print msg
            origKey = parseKey['destination_key']
            execExpr = (('a = slice(' + origKey) + ',1,200)')
            h2e.exec_expr(h2o.nodes[0], execExpr, 'a', timeoutSecs=30)
            newParseKey = {'destination_key': 'a', }
            print ('\n' + csvFilepattern)
            start = time.time()
            print 'Temporarily hacking to do nothing instead of RF on the parsed file'
            for k in importFullList:
                deleteKey = k['key']
                if ((csvFilename in deleteKey) and (not ('.hex' in deleteKey))):
                    print '\nRemoving', deleteKey
                    removeKeyResult = h2o.nodes[0].remove_key(key=deleteKey)
            h2o.tear_down_cloud()
            if (not localhost):
                print 'Waiting 30 secs before building cloud again (sticky ports?)'
                time.sleep(30)
            sys.stdout.write('.')
            sys.stdout.flush()
