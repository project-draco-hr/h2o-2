{
  if (!isRunning(self()))   throw new JobCancelledException();
  if (glmt._validate) {
    _model.setAndTestValidation(_lambdaIdx,glmt._val);
    _model.clone().update(self());
  }
  final double l1pen=alpha[0] * lambda[_lambdaIdx] * glmt._n;
  final double l2pen=(1 - alpha[0]) * lambda[_lambdaIdx] * glmt._n;
  if (glmt._validate && glmt._computeGradient) {
    final double[] grad=glmt.gradient(l2pen);
    ADMMSolver.subgrad(alpha[0],lambda[_lambdaIdx],glmt._beta,grad);
    double err=0;
    for (    double d : grad)     if (d > err)     err=d;
 else     if (d < -err)     err=-d;
    System.out.println("glm grad = " + err);
    if (err <= GLM_GRAD_SUCC) {
      Log.info("GLM converged by reaching small enough gradient/subgradient (grad = " + err + ").");
      nextLambda(glmt,glmt._val);
      return;
    }
  }
  if (glmt._beta != null && higher_accuracy && _glm.family != Family.tweedie) {
    double objval=glmt._val.residual_deviance / glmt._n + 0.5 * l2pen * l2norm(glmt._beta);
    if (_lastResult != null && needLineSearch(glmt._beta,objval,1)) {
      new GLMTask.GLMLineSearchTask(GLM2.this,_dinfo,_glm,_lastResult._glmt._beta,glmt._beta,1e-8,new LineSearchIteration()).asyncExec(_dinfo._adaptedFrame);
      return;
    }
    _lastResult=new IterationInfo(GLM2.this._iter - 1,objval,glmt);
  }
  final double[] newBeta=glmt._beta != null ? glmt._beta.clone() : MemoryManager.malloc8d(glmt._xy.length);
  double[] newBetaDeNorm=null;
  ADMMSolver slvr=new ADMMSolver(lambda[_lambdaIdx],alpha[0],ADMM_GRAD_EPS,_addedL2);
  slvr.solve(glmt._gram,glmt._xy,glmt._yy,newBeta);
  _addedL2=slvr._addedL2;
  if (Utils.hasNaNsOrInfs(newBeta)) {
    Log.info("GLM forcibly converged by getting NaNs and/or Infs in beta");
  }
 else {
    if (_dinfo._standardize) {
      newBetaDeNorm=newBeta.clone();
      double norm=0.0;
      final int numoff=newBeta.length - _dinfo._nums - 1;
      for (int i=numoff; i < newBeta.length - 1; i++) {
        double b=newBetaDeNorm[i] * _dinfo._normMul[i - numoff];
        norm+=b * _dinfo._normSub[i - numoff];
        newBetaDeNorm[i]=b;
      }
      newBetaDeNorm[newBetaDeNorm.length - 1]-=norm;
    }
    _model.setLambdaSubmodel(_lambdaIdx,newBetaDeNorm == null ? newBeta : newBetaDeNorm,newBetaDeNorm == null ? null : newBeta,_iter);
    if (_glm.family == Family.gaussian) {
      nextLambda(glmt,newBeta);
    }
 else     if (beta_diff(glmt._beta,newBeta) < beta_epsilon || _iter == max_iter) {
      Log.info("GLM converged.");
      if (!glmt._validate || !glmt._computeGradient) {
        new GLMIterationTask(GLM2.this,_dinfo,_glm,false,true,_glm.family != Family.gaussian,newBeta,_ymu,_reg,new H2OCallback<GLMIterationTask>(){
          @Override public void callback(          GLMIterationTask glmt2){
            checkGradient(glmt,newBeta,glmt2._val,glmt2.gradient(lambda[_lambdaIdx] * (1 - alpha[0])));
          }
        }
).asyncExec(_dinfo._adaptedFrame);
      }
 else {
        checkGradient(glmt,newBeta,glmt._val,glmt.gradient(lambda[_lambdaIdx] * (1 - alpha[0])));
      }
    }
 else {
      final boolean validate=higher_accuracy || (_iter % 5) == 0;
      ++_iter;
      new GLMIterationTask(GLM2.this,_dinfo,glmt._glm,true,validate,validate,newBeta,_ymu,_reg,new Iteration()).asyncExec(_dinfo._adaptedFrame);
    }
  }
}
