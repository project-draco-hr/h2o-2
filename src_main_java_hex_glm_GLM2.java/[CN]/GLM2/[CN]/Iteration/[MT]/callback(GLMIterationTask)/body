{
  Log.info("GLM2 iteration(" + _iter + ") done in "+ (System.currentTimeMillis() - start)+ "ms");
  if (!isRunning(self()))   throw new JobCancelledException();
  if (glmt._gram != null && _activeData.fullN() < 100) {
    System.out.println("GRAM");
    System.out.println(Utils.pprint(glmt._gram.getXX()));
    System.out.println("   ");
  }
  currentLambdaIter++;
  if (glmt._val != null) {
    if (!(glmt._val.residual_deviance < glmt._val.null_deviance)) {
      if (!highAccuracy()) {
        Log.info("GLM2 reached negative explained deviance without line-search, rerunning with high accuracy settings.");
        setHighAccuracy();
        if (_lastResult != null)         new GLMIterationTask(GLM2.this,_activeData,glmt._glm,true,true,true,_lastResult._glmt._beta,_ymu,_reg,new Iteration()).asyncExec(_activeFrame);
 else         if (_lambdaIdx > 2)         new GLMIterationTask(GLM2.this,_activeData,glmt._glm,true,true,true,_model.submodels[_lambdaIdx - 1].norm_beta,_ymu,_reg,new Iteration()).asyncExec(_activeFrame);
 else         new GLMIterationTask(GLM2.this,_activeData,glmt._glm,true,false,false,null,_ymu,_reg,new Iteration()).asyncExec(_activeFrame);
        _lastResult=null;
        return;
      }
    }
    _model.setAndTestValidation(_lambdaIdx,glmt._val);
    _model.clone().update(self());
  }
  if (glmt._val != null && glmt._computeGradient) {
    final double[] grad=glmt.gradient(l2pen());
    ADMMSolver.subgrad(alpha[0],lambda[_lambdaIdx],glmt._beta,grad);
    double err=0;
    for (    double d : grad)     if (d > err)     err=d;
 else     if (d < -err)     err=-d;
    Log.info("GLM2 gradient after " + _iter + " iterations = "+ err);
    if (err <= GLM_GRAD_EPS) {
      Log.info("GLM2 converged with max |subgradient| = " + err);
      setNewBeta(glmt._beta);
      nextLambda(glmt,glmt._beta);
      return;
    }
  }
  if (glmt._beta != null && glmt._val != null && glmt._computeGradient && _glm.family != Family.tweedie) {
    double objval=glmt._val.residual_deviance / glmt._n + 0.5 * l2pen() * l2norm(glmt._beta) + l1pen() * l1norm(glmt._beta);
    if (_lastResult != null && needLineSearch(glmt._beta,objval,1)) {
      if (!highAccuracy()) {
        setHighAccuracy();
        if (_lastResult._iter < (_iter - 2)) {
          new GLMIterationTask(GLM2.this,_dinfo,glmt._glm,true,true,true,_lastResult._glmt._beta,_ymu,_reg,new Iteration()).asyncExec(_activeFrame);
          return;
        }
      }
      new GLMTask.GLMLineSearchTask(GLM2.this,_dinfo,_glm,_lastResult._glmt._beta,glmt._beta,1e-8,glmt._n,alpha[0],lambda[_lambdaIdx],new LineSearchIteration()).asyncExec(_activeFrame);
      return;
    }
    _lastResult=new IterationInfo(GLM2.this._iter - 1,objval,glmt,_activeCols);
  }
  final double[] newBeta=glmt._beta != null ? glmt._beta.clone() : MemoryManager.malloc8d(glmt._xy.length);
  double[] newBetaDeNorm=null;
  ADMMSolver slvr=new ADMMSolver(lambda[_lambdaIdx],alpha[0],ADMM_GRAD_EPS,_addedL2);
  slvr.solve(glmt._gram,glmt._xy,glmt._yy,newBeta);
  _addedL2=slvr._addedL2;
  if (Utils.hasNaNsOrInfs(newBeta)) {
    Log.info("GLM2 forcibly converged by getting NaNs and/or Infs in beta");
    nextLambda(glmt,glmt._beta);
    return;
  }
 else {
    setNewBeta(newBeta);
    if (_glm.family == Family.gaussian || beta_diff(glmt._beta,newBeta) < beta_epsilon || _iter == max_iter)     nextLambda(glmt,newBeta);
 else {
      final boolean validate=higher_accuracy || (currentLambdaIter % 5) == 0;
      ++_iter;
      new GLMIterationTask(GLM2.this,_activeData,glmt._glm,true,validate,validate,newBeta,_ymu,_reg,new Iteration()).asyncExec(_activeFrame);
    }
  }
}
