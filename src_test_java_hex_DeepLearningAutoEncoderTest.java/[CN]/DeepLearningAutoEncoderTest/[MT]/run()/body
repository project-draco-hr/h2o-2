{
  long seed=0xDECAF;
  Key file=NFSFileVec.make(find_test_file(PATH));
  Frame frame=ParseDataset2.parse(Key.make(),new Key[]{file});
  DeepLearning p=new DeepLearning();
  p.source=frame;
  p.autoencoder=true;
  p.response=frame.vecs()[0];
  p.seed=seed;
  p.hidden=new int[]{10,5};
  p.adaptive_rate=true;
  p.l1=1e-4;
  p.l2=1e-4;
  p.activation=DeepLearning.Activation.Tanh;
  p.loss=DeepLearning.Loss.MeanSquare;
  p.epochs=1000;
  p.force_load_balance=true;
  p.invoke();
  DeepLearningModel mymodel=UKV.get(p.dest());
  double quantile=0.99;
  final Vec l2=mymodel.scoreAutoEncoder(frame);
  double thres=mymodel.calcOutlierThreshold(l2,quantile);
  Log.info("L2 norm of reconstruction error (in normalized space):");
  StringBuilder sb=new StringBuilder();
  sb.append("Mean reconstruction error: " + l2.mean() + "\n");
  sb.append("The following points are reconstructed with an error above the " + quantile * 100 + "-th percentile - outliers?\n");
  for (long i=0; i < l2.length(); i++) {
    if (l2.at(i) > thres) {
      sb.append(String.format("row %d : l2 error = %5f\n",i,l2.at(i)));
    }
  }
  Log.info(sb);
  assert(DKV.get(frame._key) != null);
  Log.info("before l2: " + H2O.store_size());
  Futures fs=new Futures();
  l2.remove(fs);
  fs.blockForPending();
  Log.info("after l2: " + H2O.store_size());
  mymodel.delete();
  Log.info("before frame: " + H2O.store_size());
  frame.delete();
  Log.info("after frame: " + H2O.store_size());
  p.delete();
}
