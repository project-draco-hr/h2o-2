def test_billion_rows_fvec(self):
    timeoutSecs = 1500
    csvFilenameAll = ['billion_rows.csv.gz']
    csvFilenameList = csvFilenameAll
    for csvFilename in csvFilenameList:
        start = time.time()
        parseResult = h2i.import_parse(bucket='home-0xdiag-datasets', path=('standard/' + csvFilename), timeoutSecs=timeoutSecs, pollTimeoutSecs=60)
        elapsed = (time.time() - start)
        print "Parse result['destination_key']:", parseResult['destination_key']
        print csvFilename, 'completed in', elapsed, 'seconds.', ('%d pct. of timeout' % ((elapsed * 100) / timeoutSecs))
        inspect = h2o_cmd.runInspect(key=parseResult['destination_key'])
        print ('\n' + csvFilename)
        kwargs = {'response': 1, 'n_folds': 0, }
        colX = 'C1'
        kwargs.update({'alpha': 0, 'lambda': 0, })
        start = time.time()
        glm = h2o_cmd.runGLM(parseResult=parseResult, timeoutSecs=timeoutSecs, **kwargs)
        elapsed = (time.time() - start)
        print 'glm (L2) end on ', csvFilename, 'took', elapsed, 'seconds.', ('%d pct. of timeout' % ((elapsed / timeoutSecs) * 100))
        h2o_glm.simpleCheckGLM(self, glm, colX, **kwargs)
        sys.stdout.write('\n.')
        sys.stdout.flush()
