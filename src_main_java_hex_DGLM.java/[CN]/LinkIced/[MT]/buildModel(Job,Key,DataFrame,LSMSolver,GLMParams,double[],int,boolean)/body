{
  Log.info("running GLM on " + data._ary._key + " with "+ data.expandedSz()+ " predictors in total, "+ (data.expandedSz() - data._dense)+ " of which are categoricals.");
  ArrayList<String> warns=new ArrayList<String>();
  long t1=System.currentTimeMillis();
  int ycolId=data._modelDataMap[data._response];
  Column ycol=data._ary._cols[ycolId];
  params.checkResponseCol(ycol,warns);
  GramMatrixFunc gramF=new GramMatrixFunc(data,params,oldBeta);
  double[] newBeta=MemoryManager.malloc8d(data.expandedSz());
  boolean converged=true;
  Gram gram=gramF.apply(job,data);
  final long nobs=gram._nobs;
  int iter=1;
  long lsmSolveTime=0;
  long t=System.currentTimeMillis();
  solve(lsm,gram,newBeta,warns);
  lsmSolveTime+=System.currentTimeMillis() - t;
  GLMModel currentModel=new GLMModel(Status.ComputingValidation,0.0f,resKey,data,data.denormalizeBeta(newBeta),newBeta,params,lsm,gram._nobs,newBeta.length,converged,iter,System.currentTimeMillis() - t1,null);
  currentModel.delete_and_lock(job.self());
  if (params._family._family != Family.gaussian)   do {
    if (oldBeta == null)     oldBeta=MemoryManager.malloc8d(data.expandedSz());
    if (job.cancelled())     throw new JobCancelledException();
    double[] b=oldBeta;
    oldBeta=(gramF._beta=newBeta);
    newBeta=b;
    gram=gramF.apply(job,data);
    if (gram.hasNaNsOrInfs())     break;
    t=System.currentTimeMillis();
    solve(lsm,gram,newBeta,warns);
    lsmSolveTime+=System.currentTimeMillis() - t;
    String[] warnings=new String[warns.size()];
    warns.toArray(warnings);
    double betaDiff=betaDiff(oldBeta,newBeta);
    converged=(betaDiff < params._betaEps);
    float progress=Math.max((float)iter / params._maxIter,Math.min((float)(params._betaEps / betaDiff),1.0f));
    currentModel=new GLMModel(Status.ComputingModel,progress,resKey,data,data.denormalizeBeta(newBeta),newBeta,params,lsm,gram._nobs,newBeta.length,converged,iter,System.currentTimeMillis() - t1,warnings);
    currentModel._lsmSolveTime=lsmSolveTime;
    currentModel.store(job.self());
  }
 while (++iter < params._maxIter && !converged);
  currentModel._lsmSolveTime=lsmSolveTime;
  currentModel._status=Status.ComputingValidation;
  currentModel.store(job.self());
  if (xval > 1)   currentModel.xvalidate(job,data._ary,xval,DEFAULT_THRESHOLDS,parallel);
 else   currentModel.validateOn(job,data._ary,data.getSamplingComplement(),DEFAULT_THRESHOLDS);
  currentModel._status=Status.Done;
  if (currentModel.rank() > nobs)   warns.add("Not enough data to compute the model (got more predictors than data points), try limit the number of columns (e.g. increase L1 regularization or run PCA first).");
  String[] warnings=new String[warns.size()];
  warns.toArray(warnings);
  currentModel._warnings=warnings;
  currentModel.unlock(job.self());
  DKV.write_barrier();
  return currentModel;
}
