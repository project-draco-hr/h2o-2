def test_B_hdfs_files(self):
    csvFilenameAll = ['3G_poker_shuffle', 'TEST-poker1000.csv', 'and-testing.data', 'arcene2_train.both', 'arcene_train.both', 'bestbuy_test.csv', 'bestbuy_train.csv', 'billion_rows.csv.gz', 'covtype.13x.data', 'covtype.13x.shuffle.data', 'covtype.169x.data', 'covtype.4x.shuffle.data', 'covtype.data', 'covtype4x.shuffle.data', 'hhp.unbalanced.012.1x11.data.gz', 'hhp.unbalanced.012.data.gz', 'hhp.unbalanced.data.gz', 'hhp2.os.noisy.0_1.data', 'hhp2.os.noisy.9_4.data', 'hhp_9_14_12.data', 'leads.csv', 'prostate_long_1G.csv']
    if (1 == 0):
        csvFilenameList = random.sample(csvFilenameAll, 8)
    else:
        csvFilenameList = csvFilenameAll
    h2b.browseTheCloud()
    timeoutSecs = 1000
    firstglm = {}
    for csvFilename in csvFilenameList:
        start = time.time()
        print 'Parsing', csvFilename
        csvPathname = ('datasets/' + csvFilename)
        parseResult = h2i.import_parse(path=csvPathname, schema='hdfs', header=0, timeoutSecs=timeoutSecs, retryDelaySecs=1.0)
        print csvFilename, '\nparse time (python)', (time.time() - start), 'seconds'
        print 'parse result:', parseResult['destination_key']
        inspect = h2o_cmd.runInspect(None, parseResult['destination_key'])
        h2o_cmd.infoFromInspect(inspect, csvPathname)
        print ('\n' + csvFilename)
