def test_summary(self):
    SYNDATASETS_DIR = h2o.make_syn_dir()
    tryList = [(10000, 1, 'cD', 300), (10000, 2, 'cE', 300)]
    timeoutSecs = 10
    trial = 1
    n = h2o.nodes[0]
    lenNodes = len(h2o.nodes)
    x = 0
    for (rowCount, colCount, key2, timeoutSecs) in tryList:
        SEEDPERFILE = random.randint(0, sys.maxint)
        x += 1
        csvFilename = (((((('syn_' + 'binary') + '_') + str(rowCount)) + 'x') + str(colCount)) + '.csv')
        csvPathname = ((SYNDATASETS_DIR + '/') + csvFilename)
        print 'Creating random', csvPathname
        legalValues = {}
        maxIntegerValue = 9
        for x in range((maxIntegerValue + 1)):
            legalValues[x] = x
        write_syn_dataset(csvPathname, rowCount, colCount, maxIntegerValue, SEEDPERFILE)
        parseKey = h2o_cmd.parseFile(None, csvPathname, key2=key2, timeoutSecs=10)
        print csvFilename, 'parse time:', parseKey['response']['time']
        print "Parse result['destination_key']:", parseKey['destination_key']
        inspect = h2o_cmd.runInspect(None, parseKey['destination_key'])
        print ('\n' + csvFilename)
        summaryResult = n.summary_page(key2)
        summary = summaryResult['summary']
        print h2o.dump_json(summary)
        columnsList = summary['columns']
        for columns in columnsList:
            N = columns['N']
            self.assertEqual(N, rowCount)
            name = columns['name']
            stype = columns['type']
            self.assertEqual(stype, 'number')
            histogram = columns['histogram']
            bin_size = histogram['bin_size']
            self.assertEqual(bin_size, 1)
            bin_names = histogram['bin_names']
            bins = histogram['bins']
            for b in bins:
                self.assertAlmostEqual(b, (0.1 * rowCount), delta=(0.01 * rowCount))
            nbins = histogram['bins']
            print '\n\n************************'
            print 'name:', name
            print 'type:', stype
            print 'N:', N
            print 'bin_size:', bin_size
            print 'len(bin_names):', len(bin_names), bin_names
            print 'len(bins):', len(bins), bins
            print 'len(nbins):', len(nbins), nbins
            if (stype != 'enum'):
                smax = columns['max']
                smin = columns['min']
                percentiles = columns['percentiles']
                thresholds = percentiles['thresholds']
                values = percentiles['values']
                mean = columns['mean']
                sigma = columns['sigma']
                print 'len(max):', len(smax), smax
                self.assertEqual(smax[0], maxIntegerValue)
                self.assertEqual(smax[1], (maxIntegerValue - 1))
                self.assertEqual(smax[2], (maxIntegerValue - 2))
                self.assertEqual(smax[3], (maxIntegerValue - 3))
                self.assertEqual(smax[4], (maxIntegerValue - 4))
                print 'len(min):', len(smin), smin
                self.assertEqual(smin[0], 0)
                self.assertEqual(smin[1], 1)
                self.assertEqual(smin[2], 2)
                self.assertEqual(smin[3], 3)
                self.assertEqual(smin[4], 4)
                print 'len(thresholds):', len(thresholds), thresholds
                print 'len(values):', len(values), values
                for v in values:
                    self.assertIn(v, legalValues, "Value in percentile 'values' is not present in the dataset")
                print 'mean:', mean
                self.assertAlmostEqual((2 * mean), maxIntegerValue, delta=0.01)
                print 'sigma:', sigma
                self.assertAlmostEqual((2 * sigma), maxIntegerValue, delta=0.01)
        sys.stdout.write('.')
        sys.stdout.flush()
        trial += 1
